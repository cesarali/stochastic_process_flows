{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gluonts.core.component import validated\n",
    "from pts import Trainer\n",
    "\n",
    "\n",
    "class TrainerForecasting(Trainer):\n",
    "    @validated()\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs: int = 100,\n",
    "        batch_size: int = 32,\n",
    "        num_batches_per_epoch: int = 50,\n",
    "        learning_rate: float = 1e-3,\n",
    "        weight_decay: float = 1e-6,\n",
    "        maximum_learning_rate: float = 1e-2,\n",
    "        clip_gradient: Optional[float] = None,\n",
    "        patience: int = None,\n",
    "        device: Optional[Union[torch.device, str]] = None,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches_per_epoch = num_batches_per_epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.maximum_learning_rate = maximum_learning_rate\n",
    "        self.clip_gradient = clip_gradient\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        net: nn.Module,\n",
    "        train_iter: DataLoader,\n",
    "        validation_iter: Optional[DataLoader] = None,\n",
    "    ) -> None:\n",
    "\n",
    "        optimizer = Adam(net.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "\n",
    "        lr_scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.maximum_learning_rate,\n",
    "            steps_per_epoch=self.num_batches_per_epoch,\n",
    "            epochs=self.epochs,\n",
    "        )\n",
    "\n",
    "        # Early stopping setup\n",
    "        best_loss = float('inf')\n",
    "        waiting = 0\n",
    "        best_net = deepcopy(net.state_dict())\n",
    "\n",
    "        # Training loop\n",
    "        for epoch_no in range(self.epochs):\n",
    "            # mark epoch start time\n",
    "            cumm_epoch_loss = 0.0\n",
    "            total = self.num_batches_per_epoch - 1\n",
    "\n",
    "            # training loop\n",
    "            with tqdm(train_iter, total=total) as it:\n",
    "                for batch_no, data_entry in enumerate(it, start=1):\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    inputs = [v.to(self.device) for v in data_entry.values()]\n",
    "\n",
    "                    loss = net(*inputs)\n",
    "\n",
    "                    if isinstance(loss, (list, tuple)):\n",
    "                        loss = loss[0]\n",
    "\n",
    "                    loss.backward()\n",
    "\n",
    "                    if self.clip_gradient is not None:\n",
    "                        nn.utils.clip_grad_norm_(net.parameters(), self.clip_gradient)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "                    cumm_epoch_loss += loss.item()\n",
    "                    avg_epoch_loss = cumm_epoch_loss / batch_no\n",
    "                    it.set_postfix(\n",
    "                        {\n",
    "                            \"epoch\": f\"{epoch_no + 1}/{self.epochs}\",\n",
    "                            \"avg_loss\": avg_epoch_loss,\n",
    "                        },\n",
    "                        refresh=False,\n",
    "                    )\n",
    "\n",
    "                    if self.num_batches_per_epoch == batch_no:\n",
    "                        break\n",
    "                it.close()\n",
    "\n",
    "            # validation loop\n",
    "            if validation_iter is not None:\n",
    "                cumm_epoch_loss_val = 0.0\n",
    "                with tqdm(validation_iter, total=total, colour=\"green\") as it:\n",
    "\n",
    "                    for batch_no, data_entry in enumerate(it, start=1):\n",
    "                        inputs = [v.to(self.device) for v in data_entry.values()]\n",
    "                        with torch.no_grad():\n",
    "                            output = net(*inputs)\n",
    "                        if isinstance(output, (list, tuple)):\n",
    "                            loss = output[0]\n",
    "                        else:\n",
    "                            loss = output\n",
    "\n",
    "                        cumm_epoch_loss_val += loss.item()\n",
    "                        avg_epoch_loss_val = cumm_epoch_loss_val / batch_no\n",
    "                        it.set_postfix(\n",
    "                            {\n",
    "                                \"epoch\": f\"{epoch_no + 1}/{self.epochs}\",\n",
    "                                \"avg_loss\": avg_epoch_loss,\n",
    "                                \"avg_val_loss\": avg_epoch_loss_val,\n",
    "                            },\n",
    "                            refresh=False,\n",
    "                        )\n",
    "\n",
    "                        if self.num_batches_per_epoch == batch_no:\n",
    "                            break\n",
    "                it.close()\n",
    "\n",
    "                # Early stopping logic\n",
    "                if avg_epoch_loss_val < best_loss:\n",
    "                    best_loss = avg_epoch_loss_val\n",
    "                    best_net = deepcopy(net.state_dict())\n",
    "                    waiting = 0\n",
    "                elif waiting > self.patience:\n",
    "                    print(f'Early stopping at epoch {epoch_no}')\n",
    "                    break\n",
    "                else:\n",
    "                    waiting += 1\n",
    "\n",
    "            # mark epoch end time and log time cost of current epoch\n",
    "\n",
    "        net.load_state_dict(best_net)\n",
    "\n",
    "# python -m tsdiff.train_forecasting --seed 1 --dataset electricity_nips --network timegrad_rnn --noise ou --epochs 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cesar\\anaconda3\\envs\\torchts\\Lib\\site-packages\\gluonts\\json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, List, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.time_feature import TimeFeature\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "from gluonts.torch.util import copy_parameters\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.transform import (\n",
    "    Transformation,\n",
    "    Chain,\n",
    "    InstanceSplitter,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    ValidationSplitSampler,\n",
    "    TestSplitSampler,\n",
    "    RenameFields,\n",
    "    AsNumpyArray,\n",
    "    ExpandDimArray,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    VstackFeatures,\n",
    "    SetFieldIfNotPresent,\n",
    "    TargetDimIndicator,\n",
    ")\n",
    "from gluonts.core.component import validated\n",
    "\n",
    "from pts.feature import (\n",
    "    fourier_time_features_from_frequency,\n",
    "    lags_for_fourier_time_features_from_frequency,\n",
    ")\n",
    "from pts.model import PyTorchEstimator\n",
    "from pts.model.utils import get_module_forward_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreEstimator(PyTorchEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        training_net: Callable,\n",
    "        prediction_net: Callable,\n",
    "        noise: str,\n",
    "        input_size: int,\n",
    "        freq: str,\n",
    "        prediction_length: int,\n",
    "        target_dim: int,\n",
    "        trainer: TrainerForecasting = TrainerForecasting(),\n",
    "        context_length: Optional[int] = None,\n",
    "        num_layers: int = 2,\n",
    "        num_cells: int = 40,\n",
    "        cell_type: str = \"GRU\",\n",
    "        num_parallel_samples: int = 100,\n",
    "        dropout_rate: float = 0.1,\n",
    "        cardinality: List[int] = [1],\n",
    "        embedding_dimension: int = 5,\n",
    "        hidden_dim: int = 100,\n",
    "        diff_steps: int = 100,\n",
    "        loss_type: str = \"l2\",\n",
    "        beta_end=0.1,\n",
    "        beta_schedule=\"linear\",\n",
    "        residual_layers=8,\n",
    "        residual_channels=8,\n",
    "        dilation_cycle_length=2,\n",
    "        scaling: bool = True,\n",
    "        pick_incomplete: bool = False,\n",
    "        lags_seq: Optional[List[int]] = None,\n",
    "        time_features: Optional[List[TimeFeature]] = None,\n",
    "        old: bool = False,\n",
    "        time_feat_dim: int = 4,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(trainer=trainer, **kwargs)\n",
    "\n",
    "        self.training_net = training_net\n",
    "        self.prediction_net = prediction_net\n",
    "        self.noise = noise\n",
    "\n",
    "        self.old = old\n",
    "\n",
    "        self.freq = freq\n",
    "        self.context_length = context_length if context_length is not None else prediction_length\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.target_dim = target_dim\n",
    "        self.time_feat_dim = time_feat_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_cells = num_cells\n",
    "        self.cell_type = cell_type\n",
    "        self.num_parallel_samples = num_parallel_samples\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.cardinality = cardinality\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "\n",
    "        self.conditioning_length = hidden_dim\n",
    "        self.diff_steps = diff_steps\n",
    "        self.loss_type = loss_type\n",
    "        self.beta_end = beta_end\n",
    "        self.beta_schedule = beta_schedule\n",
    "        self.residual_layers = residual_layers\n",
    "        self.residual_channels = residual_channels\n",
    "        self.dilation_cycle_length = dilation_cycle_length\n",
    "\n",
    "        self.lags_seq = (\n",
    "            lags_seq\n",
    "            if lags_seq is not None\n",
    "            else lags_for_fourier_time_features_from_frequency(freq_str=freq)\n",
    "        )\n",
    "\n",
    "        self.time_features = (\n",
    "            time_features\n",
    "            if time_features is not None\n",
    "            else fourier_time_features_from_frequency(self.freq)\n",
    "        )\n",
    "\n",
    "        self.history_length = self.context_length + max(self.lags_seq)\n",
    "        self.pick_incomplete = pick_incomplete\n",
    "        self.scaling = scaling\n",
    "\n",
    "        self.train_sampler = ExpectedNumInstanceSampler(\n",
    "            num_instances=1.0,\n",
    "            min_past=0 if pick_incomplete else self.history_length,\n",
    "            min_future=prediction_length,\n",
    "        )\n",
    "\n",
    "        self.validation_sampler = ValidationSplitSampler(\n",
    "            min_past=0 if pick_incomplete else self.history_length,\n",
    "            min_future=prediction_length,\n",
    "        )\n",
    "\n",
    "    def create_transformation(self) -> Transformation:\n",
    "        return Chain(\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.TARGET,\n",
    "                    expected_ndim=2,\n",
    "                ),\n",
    "                # maps the target to (1, T)\n",
    "                # if the target data is uni dimensional\n",
    "                ExpandDimArray(\n",
    "                    field=FieldName.TARGET,\n",
    "                    axis=None,\n",
    "                ),\n",
    "                AddObservedValuesIndicator(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.OBSERVED_VALUES,\n",
    "                ),\n",
    "                AddTimeFeatures(\n",
    "                    start_field=FieldName.START,\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.FEAT_TIME,\n",
    "                    time_features=self.time_features,\n",
    "                    pred_length=self.prediction_length,\n",
    "                ),\n",
    "                VstackFeatures(\n",
    "                    output_field=FieldName.FEAT_TIME,\n",
    "                    input_fields=[FieldName.FEAT_TIME],\n",
    "                ),\n",
    "                SetFieldIfNotPresent(field=FieldName.FEAT_STATIC_CAT, value=[0]),\n",
    "                TargetDimIndicator(\n",
    "                    field_name=\"target_dimension_indicator\",\n",
    "                    target_field=FieldName.TARGET,\n",
    "                ),\n",
    "                AsNumpyArray(field=FieldName.FEAT_STATIC_CAT, expected_ndim=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def create_instance_splitter(self, mode: str):\n",
    "        assert mode in [\"training\", \"validation\", \"test\"]\n",
    "\n",
    "        instance_sampler = {\n",
    "            \"training\": self.train_sampler,\n",
    "            \"validation\": self.validation_sampler,\n",
    "            \"test\": TestSplitSampler(),\n",
    "        }[mode]\n",
    "\n",
    "        return InstanceSplitter(\n",
    "            target_field=FieldName.TARGET,\n",
    "            is_pad_field=FieldName.IS_PAD,\n",
    "            start_field=FieldName.START,\n",
    "            forecast_start_field=FieldName.FORECAST_START,\n",
    "            instance_sampler=instance_sampler,\n",
    "            past_length=self.history_length,\n",
    "            future_length=self.prediction_length,\n",
    "            time_series_fields=[\n",
    "                FieldName.FEAT_TIME,\n",
    "                FieldName.OBSERVED_VALUES,\n",
    "            ],\n",
    "        ) + (\n",
    "            RenameFields(\n",
    "                {\n",
    "                    f\"past_{FieldName.TARGET}\": f\"past_{FieldName.TARGET}_cdf\",\n",
    "                    f\"future_{FieldName.TARGET}\": f\"future_{FieldName.TARGET}_cdf\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def create_training_network(self, device: torch.device):\n",
    "        return self.training_net(\n",
    "            noise=self.noise,\n",
    "            input_size=self.input_size,\n",
    "            target_dim=self.target_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            num_cells=self.num_cells,\n",
    "            cell_type=self.cell_type,\n",
    "            history_length=self.history_length,\n",
    "            context_length=self.context_length,\n",
    "            prediction_length=self.prediction_length,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            cardinality=self.cardinality,\n",
    "            embedding_dimension=self.embedding_dimension,\n",
    "            diff_steps=self.diff_steps,\n",
    "            loss_type=self.loss_type,\n",
    "            beta_end=self.beta_end,\n",
    "            beta_schedule=self.beta_schedule,\n",
    "            residual_layers=self.residual_layers,\n",
    "            residual_channels=self.residual_channels,\n",
    "            dilation_cycle_length=self.dilation_cycle_length,\n",
    "            lags_seq=self.lags_seq,\n",
    "            scaling=self.scaling,\n",
    "            conditioning_length=self.conditioning_length,\n",
    "            time_feat_dim=self.time_feat_dim,\n",
    "        ).to(device)\n",
    "\n",
    "    def create_predictor(\n",
    "        self,\n",
    "        transformation: Transformation,\n",
    "        trained_network: Any,\n",
    "        device: torch.device,\n",
    "    ) -> Predictor:\n",
    "        prediction_network = self.prediction_net(\n",
    "            noise=self.noise,\n",
    "            input_size=self.input_size,\n",
    "            target_dim=self.target_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            num_cells=self.num_cells,\n",
    "            cell_type=self.cell_type,\n",
    "            history_length=self.history_length,\n",
    "            context_length=self.context_length,\n",
    "            prediction_length=self.prediction_length,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            cardinality=self.cardinality,\n",
    "            embedding_dimension=self.embedding_dimension,\n",
    "            diff_steps=self.diff_steps,\n",
    "            loss_type=self.loss_type,\n",
    "            beta_end=self.beta_end,\n",
    "            beta_schedule=self.beta_schedule,\n",
    "            residual_layers=self.residual_layers,\n",
    "            residual_channels=self.residual_channels,\n",
    "            dilation_cycle_length=self.dilation_cycle_length,\n",
    "            lags_seq=self.lags_seq,\n",
    "            scaling=self.scaling,\n",
    "            conditioning_length=self.conditioning_length,\n",
    "            num_parallel_samples=self.num_parallel_samples,\n",
    "            time_feat_dim=self.time_feat_dim,\n",
    "        ).to(device)\n",
    "\n",
    "        copy_parameters(trained_network, prediction_network)\n",
    "        input_names = get_module_forward_input_names(prediction_network)\n",
    "        prediction_splitter = self.create_instance_splitter(\"test\")\n",
    "\n",
    "        return PyTorchPredictor(\n",
    "            input_transform=transformation + prediction_splitter,\n",
    "            input_names=input_names,\n",
    "            prediction_net=prediction_network,\n",
    "            batch_size=self.trainer.batch_size,\n",
    "            freq=self.freq,\n",
    "            prediction_length=self.prediction_length,\n",
    "            device=device,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from torchtyping import TensorType\n",
    "\n",
    "import numpy as np\n",
    "import scipy.fftpack\n",
    "from functools import lru_cache\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Normal(nn.Module):\n",
    "    def __init__(self, dim: int, **kwargs):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, *shape, **kwargs):\n",
    "        return torch.randn(*shape, self.dim)\n",
    "\n",
    "    def covariance(self, **kwargs):\n",
    "        return torch.eye(self.dim)\n",
    "\n",
    "\n",
    "class Wiener(nn.Module):\n",
    "    \"\"\"\n",
    "    Wiener process / Brownian motion.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        t: Union[TensorType['seq_len'], TensorType[..., 'seq_len', 1]],\n",
    "        **kwargs,\n",
    "    ) -> Union[TensorType['seq_len'], TensorType[..., 'seq_len', 'dim']]:\n",
    "        one_dimensional = len(t.shape) == 1\n",
    "\n",
    "        if one_dimensional:\n",
    "            t = t.unsqueeze(-1)\n",
    "        t = t.repeat_interleave(self.dim, dim=-1)\n",
    "\n",
    "        dt = torch.diff(t, dim=-2, prepend=torch.zeros_like(t[...,:1,:]).to(t))\n",
    "        dw = torch.randn_like(dt) * dt.clamp(1e-5).sqrt()\n",
    "        w = dw.cumsum(dim=-2)\n",
    "\n",
    "        if one_dimensional and self.dim == 1:\n",
    "            w = w.squeeze(-1)\n",
    "        return w\n",
    "\n",
    "\n",
    "class OrnsteinUhlenbeck(nn.Module):\n",
    "    \"\"\"\n",
    "    Ornstein-Uhlenbeck process.\n",
    "\n",
    "    Args:\n",
    "        theta: Diffusion param, higher value = spikier (float)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int, theta: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.theta = theta\n",
    "        self.wiener = Wiener(dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        *args,\n",
    "        t: TensorType[..., 'seq_len', 1],\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 'seq_len', 'dim']:\n",
    "\n",
    "        delta = torch.diff(t, dim=-2, prepend=torch.zeros_like(t[...,:1,:]))\n",
    "        coeff = torch.exp(-self.theta * delta)\n",
    "\n",
    "        sample = []\n",
    "\n",
    "        x = torch.randn(*t.shape[:-2], 1, self.dim).to(t)\n",
    "        for i in range(coeff.shape[-2]):\n",
    "            z = torch.randn(*t.shape[:-2], 1, self.dim).to(t)\n",
    "            c = coeff[...,i,None,:]\n",
    "            x = c * x + torch.sqrt(1 - c**2) * z\n",
    "            sample.append(x)\n",
    "\n",
    "        sample = torch.cat(sample, dim=-2)\n",
    "        return sample\n",
    "\n",
    "    def covariance(\n",
    "        self,\n",
    "        t: TensorType[..., 'seq_len', 1],\n",
    "        diag_epsilon: float = 1e-4,\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 'seq_len', 'seq_len']:\n",
    "        t = t.squeeze(-1)\n",
    "        diag = torch.eye(t.shape[-1]).to(t) * diag_epsilon\n",
    "        cov = torch.exp(-(t.unsqueeze(-1) - t.unsqueeze(-2)).abs() * self.theta)\n",
    "        return cov + diag\n",
    "\n",
    "    def covariance_cholesky(self, t: TensorType[..., 'seq_len', 1]) -> TensorType[..., 'seq_len', 'seq_len']:\n",
    "        return torch.linalg.cholesky(self.covariance(t))\n",
    "\n",
    "    def covariance_inverse(self, t: TensorType[..., 'seq_len', 1]) -> TensorType[..., 'seq_len', 'seq_len']:\n",
    "        return torch.linalg.inv(self.covariance(t))\n",
    "\n",
    "\n",
    "class GaussianProcess(nn.Module):\n",
    "    \"\"\"\n",
    "    Gaussian random field for one-dimensional (temporal) data.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int, sigma: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        *args,\n",
    "        t: TensorType[..., 'N', 1],\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 'N', 'dim']:\n",
    "        # If N is very large this could become slow\n",
    "        # In that case, consider using sparse GP\n",
    "        L = self.covariance_cholesky(t)\n",
    "        e = torch.randn(*t.shape[:-1], self.dim).to(t)\n",
    "        return L @ e\n",
    "\n",
    "    def covariance(\n",
    "        self,\n",
    "        t: TensorType[..., 'N', 1],\n",
    "        diag_epsilon: float = 1e-4,\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 'N', 'N']:\n",
    "        if t.shape[-1] != 1 or len(t.shape) < 2:\n",
    "            t = t.unsqueeze(-1)\n",
    "        distance = t - t.transpose(-1, -2)\n",
    "        diag = torch.eye(t.shape[-2]).to(t) * diag_epsilon\n",
    "        return torch.exp(-torch.square(distance / self.sigma)) + diag\n",
    "\n",
    "    def covariance_cholesky(self, t: TensorType[..., 'N', 1]) -> TensorType[..., 'N', 'N']:\n",
    "        return torch.linalg.cholesky(self.covariance(t))\n",
    "\n",
    "    def covariance_inverse(self, t: TensorType[..., 'N', 1]) -> TensorType[..., 'N', 'N']:\n",
    "        return torch.linalg.inv(self.covariance(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "def get_beta_scheduler(name: str) -> Callable:\n",
    "    if name == 'linear':\n",
    "        return BetaLinear\n",
    "\n",
    "def get_loss_weighting(name: str) -> Callable:\n",
    "    if name == 'exponential':\n",
    "        return exponential_loss_weighting\n",
    "\n",
    "class BetaLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear scheduling for beta.\n",
    "    Input t is always from interval [0, 1].\n",
    "\n",
    "    Args:\n",
    "        start: Lower bound (float)\n",
    "        end: Upper bound (float)\n",
    "    \"\"\"\n",
    "    def __init__(self, start: float, end: float):\n",
    "        super().__init__()\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "    def forward(self, t: Tensor) -> Tensor:\n",
    "        return self.start * (1 - t) + self.end * t\n",
    "\n",
    "    def integral(self, t: Tensor) -> Tensor:\n",
    "        return 0.5 * (self.end - self.start) * t.square() + self.start * t\n",
    "\n",
    "\n",
    "def exponential_loss_weighting(beta_fn, i):\n",
    "    return 1 - torch.exp(-beta_fn.integral(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple, Optional, Union\n",
    "from torchtyping import TensorType\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as td\n",
    "\n",
    "from torchsde import sdeint\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "class ContinuousDiffusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Continuous diffusion using SDEs (https://arxiv.org/abs/2011.13456)\n",
    "\n",
    "    Args:\n",
    "        dim: Dimension of data\n",
    "        beta_fn: Scheduler for noise levels\n",
    "        t1: Final diffusion time\n",
    "        noise_fn: Type of noise\n",
    "        predict_gaussian_noise: Whether to approximate score with unit normal\n",
    "        loss_weighting: Function returning loss weights given diffusion time\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        beta_fn: Callable,\n",
    "        t1: float = 1.0,\n",
    "        noise_fn: Callable = None,\n",
    "        loss_weighting: Callable = None,\n",
    "        is_time_series: bool = False,\n",
    "        predict_gaussian_noise: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.t1 = t1\n",
    "        self.predict_gaussian_noise = predict_gaussian_noise\n",
    "        self.is_time_series = is_time_series\n",
    "\n",
    "        self.beta_fn = beta_fn\n",
    "        self.noise = noise_fn\n",
    "        self.loss_weighting = partial(loss_weighting or (lambda beta, i: 1), beta_fn)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: TensorType[..., 'dim'],\n",
    "        i: TensorType[..., 1],\n",
    "        _return_all: Optional[bool] = False, # For internal use only\n",
    "        **kwargs,\n",
    "    ) -> Tuple[TensorType[..., 'dim'], TensorType[..., 'dim']]:\n",
    "\n",
    "        noise_gaussian = torch.randn_like(x)\n",
    "\n",
    "        if self.is_time_series:\n",
    "            cov = self.noise.covariance(**kwargs)\n",
    "            L = torch.linalg.cholesky(cov)\n",
    "            noise = L @ noise_gaussian\n",
    "        else:\n",
    "            noise = noise_gaussian\n",
    "\n",
    "        beta_int = self.beta_fn.integral(i)\n",
    "\n",
    "        mean = x * torch.exp(-beta_int / 2)\n",
    "        std = (1 - torch.exp(-beta_int)).clamp(1e-5).sqrt()\n",
    "\n",
    "        y = mean + std * noise\n",
    "\n",
    "        if _return_all:\n",
    "            return y, noise, mean, std, cov if self.is_time_series else None\n",
    "\n",
    "        if self.predict_gaussian_noise:\n",
    "            return y, noise_gaussian\n",
    "        else:\n",
    "            return y, noise\n",
    "\n",
    "    def get_loss(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        x: TensorType[..., 'dim'],\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 1]:\n",
    "\n",
    "        i = torch.rand(x.shape[0], *(1,) * len(x.shape[1:])).expand_as(x[...,:1]).to(x)\n",
    "        i = i * self.t1\n",
    "\n",
    "        x_noisy, noise = self.forward(x, i, **kwargs)\n",
    "\n",
    "        pred_noise = model(x_noisy, i=i, **kwargs)\n",
    "        loss = self.loss_weighting(i) * (pred_noise - noise)**2\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _get_score(self, model, x, i, L=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns score: ∇_xs log p(xs)\n",
    "        \"\"\"\n",
    "        if isinstance(i, float):\n",
    "            i = torch.Tensor([i]).to(x)\n",
    "        if i.shape[:-1] != x.shape[:-1]:\n",
    "            i = i.view(*(1,) * len(x.shape)).expand_as(x[...,:1])\n",
    "\n",
    "        beta_int = self.beta_fn.integral(i)\n",
    "        std = (1 - torch.exp(-beta_int)).clamp(1e-5).sqrt()\n",
    "\n",
    "        noise = model(x, i=i, **kwargs)\n",
    "\n",
    "        if L is not None:\n",
    "            # We have to compute the score using -Sigma.inv() @ noise / std\n",
    "            # assuming noise~N(0, Sigma).\n",
    "            # If `predict_gaussian_noise=False`, compute (LL^T).inv()\n",
    "            # Else, we can simplify (LL^T).inv() @ L @ noise\n",
    "            # to (L^T).inv() @ noise, where noise~N(0, I).\n",
    "            # So we anyways have to do (L^T).inv(), and sometimes L.inv()\n",
    "            if not self.predict_gaussian_noise:\n",
    "                noise = torch.linalg.solve_triangular(L, noise, upper=False)\n",
    "            noise = torch.linalg.solve_triangular(L.transpose(-1, -2), noise, upper=True)\n",
    "\n",
    "        score = -noise / std\n",
    "        return score\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def log_prob(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        x: Union[TensorType[..., 'dim'], TensorType[..., 'seq_len', 'dim']],\n",
    "        num_samples: int = 1,\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 1]:\n",
    "        model.train() # Allows backprop through RNN\n",
    "        self._e = torch.randn(num_samples, *x.shape).to(x)\n",
    "\n",
    "        if self.is_time_series:\n",
    "            cov = self.noise.covariance(**kwargs)\n",
    "            L = torch.linalg.cholesky(cov)\n",
    "        else:\n",
    "            L = None\n",
    "\n",
    "        def drift(i, state):\n",
    "            y, _ = state\n",
    "            with torch.set_grad_enabled(True):\n",
    "                y = y.requires_grad_(True)\n",
    "                score = self._get_score(model, y, i=i, L=L, **kwargs)\n",
    "                if self.is_time_series:\n",
    "                    # Have to include `cov` since g(t) = \"scalar\" * L @ dW\n",
    "                    score = cov @ score\n",
    "                dy = -0.5 * self.beta_fn(i) * (y + score)\n",
    "                divergence = divergence_approx(dy, y, self._e, num_samples=num_samples)\n",
    "            return dy, -divergence\n",
    "\n",
    "        interval = torch.Tensor([0, self.t1]).to(x)\n",
    "\n",
    "        # states = odeint(drift, (x, torch.zeros_like(x).to(x)), interval, rtol=1e-6, atol=1e-5)\n",
    "        states = odeint(drift, (x, torch.zeros_like(x).to(x)), interval,\n",
    "            method='rk4', options={'step_size': .01})\n",
    "        y, div = states[0][-1], states[1][-1]\n",
    "\n",
    "        if self.is_time_series:\n",
    "            p0 = td.Independent(torch.distributions.MultivariateNormal(\n",
    "                torch.zeros_like(y).transpose(-1, -2),\n",
    "                cov.unsqueeze(-3).repeat_interleave(self.dim, dim=-3),\n",
    "            ), 1)\n",
    "            log_prob = p0.log_prob(y.transpose(-1, -2)) - div.sum([-1, -2])\n",
    "            log_prob = log_prob / x.shape[-2]\n",
    "        else:\n",
    "            p0 = td.Independent(td.Normal(torch.zeros_like(y), torch.ones_like(y)), 1)\n",
    "            log_prob = p0.log_prob(y) - div.sum(-1)\n",
    "\n",
    "        return log_prob.unsqueeze(-1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        num_samples: int,\n",
    "        device: str = None,\n",
    "        use_ode: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> TensorType['num_samples', 'dim']:\n",
    "        if isinstance(num_samples, int):\n",
    "            num_samples = (num_samples,)\n",
    "\n",
    "        sampler = self.ode_sample if use_ode else self.sde_sample\n",
    "        return sampler(model, num_samples, device, **kwargs)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ode_sample(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        num_samples: int,\n",
    "        device: str = None,\n",
    "        **kwargs,\n",
    "    ) -> TensorType['num_samples', 'dim']:\n",
    "        if self.is_time_series:\n",
    "            cov = self.noise.covariance(**kwargs)\n",
    "            L = torch.linalg.cholesky(cov)\n",
    "        else:\n",
    "            L = None\n",
    "\n",
    "        def drift(i, y):\n",
    "            score = self._get_score(model, y, i=i, L=L, **kwargs)\n",
    "            if self.is_time_series:\n",
    "                # Have to include `cov` since g(t) = \"scalar\" * L @ dW\n",
    "                score = cov @ score\n",
    "            return -0.5 * self.beta_fn(i) * (y + score)\n",
    "\n",
    "        x = self.noise(*num_samples, **kwargs).to(device)\n",
    "        t = torch.Tensor([self.t1, 0]).to(device)\n",
    "        y = odeint(drift, x, t, method='rk4', options={'step_size': .01})[1]\n",
    "        # y = odeint(drift, x, t, rtol=1e-6, atol=1e-5)[1]\n",
    "\n",
    "        return y\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sde_sample(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        num_samples: int,\n",
    "        device: str = None,\n",
    "        **kwargs,\n",
    "    ) -> TensorType['num_samples', 'dim']:\n",
    "\n",
    "        if self.is_time_series:\n",
    "            cov = self.noise.covariance(**kwargs)\n",
    "            L = torch.linalg.cholesky(cov)\n",
    "        else:\n",
    "            L = None\n",
    "\n",
    "        is_time_series = self.is_time_series\n",
    "\n",
    "        x = self.noise(*num_samples, **kwargs).to(device)\n",
    "        shape = x.shape\n",
    "        x = x.transpose(-2, -1).flatten(0, -2)\n",
    "\n",
    "        class SDE(nn.Module):\n",
    "            noise_type = 'general' if is_time_series else 'diagonal'\n",
    "            sde_type = 'ito'\n",
    "\n",
    "            def __init__(self, beta_fn, _get_score):\n",
    "                super().__init__()\n",
    "                self.beta_fn = beta_fn\n",
    "                self._get_score = _get_score\n",
    "\n",
    "            def f(self, i, inp):\n",
    "                i = -i\n",
    "                inp = inp.view(*shape) # Reshape back to original\n",
    "\n",
    "                score = self._get_score(model, inp, i=i, L=L, **kwargs)\n",
    "                if is_time_series:\n",
    "                    score = cov @ score\n",
    "\n",
    "                dx = self.beta_fn(i) * (0.5 * inp + score)\n",
    "\n",
    "                if is_time_series:\n",
    "                    return dx.transpose(-1, -2).flatten(0, -2)\n",
    "                return dx.view(-1, shape[-1])\n",
    "\n",
    "            def g(self, i, inp):\n",
    "                i = -i\n",
    "                beta = -self.beta_fn(i).sqrt()\n",
    "\n",
    "                if is_time_series:\n",
    "                    return (beta * L).repeat_interleave(shape[-1], dim=0)\n",
    "                return beta.view(1, 1).repeat(np.prod(shape[:-1]), shape[-1]).to(device)\n",
    "\n",
    "        sde = SDE(self.beta_fn, self._get_score)\n",
    "        interval = torch.Tensor([-self.t1, 0]).to(device) # Time from -t1 to 0\n",
    "\n",
    "        step_size = self.t1 / 100\n",
    "        if not is_time_series:\n",
    "            x = x.view(-1, shape[-1])\n",
    "        else:\n",
    "            x = x.view(-1, shape[-2])\n",
    "        y = sdeint(sde, x, interval, dt=step_size)[-1]\n",
    "        y = y.view(*shape)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class ContinuousGaussianDiffusion(ContinuousDiffusion):\n",
    "    \"\"\" Continuous diffusion using Gaussian noise \"\"\"\n",
    "    def __init__(self, dim: int, beta_fn: Callable, predict_gaussian_noise=None, **kwargs):\n",
    "        super().__init__(dim, beta_fn, noise_fn=Normal(dim), predict_gaussian_noise=True, **kwargs)\n",
    "\n",
    "\n",
    "class ContinuousOUDiffusion(ContinuousDiffusion):\n",
    "    \"\"\" Continuous diffusion using noise coming from an OU process \"\"\"\n",
    "    def __init__(self, dim: int, beta_fn: Callable, predict_gaussian_noise: bool = False, theta: float = 0.5, **kwargs):\n",
    "        super().__init__(\n",
    "            dim=dim,\n",
    "            beta_fn=beta_fn,\n",
    "            noise_fn=OrnsteinUhlenbeck(dim, theta=theta),\n",
    "            predict_gaussian_noise=predict_gaussian_noise,\n",
    "            is_time_series=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "class ContinuousGPDiffusion(ContinuousDiffusion):\n",
    "    \"\"\" Continuous diffusion using noise coming from a Gaussian process \"\"\"\n",
    "    def __init__(self, dim: int, beta_fn: Callable, predict_gaussian_noise: bool = False, sigma: float = 0.1, **kwargs):\n",
    "        super().__init__(\n",
    "            dim=dim,\n",
    "            beta_fn=beta_fn,\n",
    "            noise_fn=GaussianProcess(dim, sigma=sigma),\n",
    "            predict_gaussian_noise=predict_gaussian_noise,\n",
    "            is_time_series=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "def divergence_approx(output, input, e, num_samples=1):\n",
    "    out = 0\n",
    "    for i in range(num_samples):\n",
    "        out += torch.autograd.grad(output, input, e[i], create_graph=True)[0].detach() * e[i]\n",
    "    return out / num_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Tuple, Union\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DiscreteDiffusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Discrete diffusion (https://arxiv.org/abs/2006.11239)\n",
    "\n",
    "    Args:\n",
    "        dim: Dimension of data\n",
    "        num_steps: Number of diffusion steps\n",
    "        beta_fn: Scheduler for noise levels\n",
    "        noise_fn: Type of noise\n",
    "        parallel_elbo: Whether to compute ELBO in parallel or not\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_steps: int,\n",
    "        beta_fn: Callable,\n",
    "        noise_fn: Callable,\n",
    "        parallel_elbo: bool = False,\n",
    "        is_time_series: bool = False,\n",
    "        predict_gaussian_noise: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_steps = num_steps\n",
    "        self.parallel_elbo = parallel_elbo\n",
    "        self.is_time_series = is_time_series\n",
    "        self.predict_gaussian_noise = predict_gaussian_noise\n",
    "\n",
    "        betas = beta_fn(torch.linspace(0, 1, num_steps))\n",
    "        alphas = torch.cumprod(1 - betas, dim=0)\n",
    "\n",
    "        self.register_buffer('betas', betas)  # Register betas as a buffer\n",
    "        self.register_buffer('alphas', alphas)  # Register alphas as a buffer\n",
    "\n",
    "        self.noise = noise_fn\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: TensorType[..., 'dim'],  # noqa: F821\n",
    "        i: TensorType[..., 1],\n",
    "        **kwargs,\n",
    "    ) -> Tuple[TensorType[..., 'dim'], TensorType[..., 'dim']]:  # noqa: F821\n",
    "\n",
    "        noise_gaussian = torch.randn_like(x)\n",
    "\n",
    "        if self.is_time_series:\n",
    "            cov = self.noise.covariance(**kwargs)\n",
    "            L = torch.linalg.cholesky(cov)\n",
    "            noise = L @ noise_gaussian\n",
    "        else:\n",
    "            noise = noise_gaussian\n",
    "\n",
    "        alpha = self.alphas[i.long()].to(x)\n",
    "        y = torch.sqrt(alpha) * x + torch.sqrt(1 - alpha) * noise\n",
    "\n",
    "        if self.predict_gaussian_noise:\n",
    "            return y, noise_gaussian\n",
    "        else:\n",
    "            return y, noise\n",
    "\n",
    "    def get_loss(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        x: TensorType[..., 'dim'],\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 'dim']:\n",
    "\n",
    "        i = torch.randint(0, self.num_steps, size=(x.shape[0],))\n",
    "        i = i.view(-1, *(1,) * len(x.shape[1:])).expand_as(x[...,:1]).to(x)\n",
    "\n",
    "        x_noisy, noise = self.forward(x, i, **kwargs)\n",
    "\n",
    "        pred_noise = model(x_noisy, i=i, **kwargs)\n",
    "        loss = (pred_noise - noise)**2\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        num_samples: Union[int, Tuple],\n",
    "        device: str = 'cpu',\n",
    "        **kwargs,\n",
    "    ) -> TensorType['*num_samples', 'dim']:\n",
    "        if isinstance(num_samples, int):\n",
    "            num_samples = (num_samples,)\n",
    "\n",
    "        x = self.noise(*num_samples, **kwargs).to(device)\n",
    "\n",
    "        if self.is_time_series and self.predict_gaussian_noise:\n",
    "            cov = self.noise.covariance(**kwargs)\n",
    "            L = torch.linalg.cholesky(cov)\n",
    "        else:\n",
    "            L = None\n",
    "\n",
    "        for diff_step in reversed(range(0, self.num_steps)):\n",
    "            alpha = self.alphas[diff_step]\n",
    "            beta = self.betas[diff_step]\n",
    "\n",
    "            # An alternative can be:\n",
    "            # alpha_prev = self.alphas[diff_step - 1]\n",
    "            # sigma = beta * (1 - alpha_prev) / (1 - alpha)\n",
    "            sigma = beta\n",
    "\n",
    "            if diff_step == 0:\n",
    "                z = 0\n",
    "            else:\n",
    "                z = self.noise(*num_samples, **kwargs).to(device)\n",
    "\n",
    "            i = torch.Tensor([diff_step]).expand_as(x[...,:1]).to(device)\n",
    "            pred_noise = model(x, i=i, **kwargs)\n",
    "\n",
    "            if L is not None:\n",
    "                pred_noise = L @ pred_noise\n",
    "\n",
    "            x = (x - beta * pred_noise / (1 - alpha).sqrt()) / (1 - beta).sqrt() + sigma.sqrt() * z\n",
    "\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def log_prob(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        x: TensorType[..., 'dim'],\n",
    "        num_samples: int = 1,\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 1]:\n",
    "        if self.is_time_series and self.predict_gaussian_noise:\n",
    "            cov = self.noise.covariance(**kwargs)\n",
    "            L = torch.linalg.cholesky(cov)\n",
    "        else:\n",
    "            L = None\n",
    "\n",
    "        func = self._elbo_parallel if self.parallel_elbo else self._elbo_sequential\n",
    "        return func(model, x, num_samples=num_samples, L=L, **kwargs)\n",
    "\n",
    "    def _elbo_parallel(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        x: TensorType[..., 'dim'],\n",
    "        L: TensorType[..., 'seq_len', 'seq_len'],\n",
    "        num_samples: int = 1,\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 1]:\n",
    "        \"\"\"\n",
    "        Computes ELBO over all diffusion steps in parallel,\n",
    "        then averages over `num_samples` runs.\n",
    "        If diffusion `num_steps` large (and `num_samples` small)\n",
    "        it will be heavy on the GPU memory.\n",
    "\n",
    "        Args:\n",
    "            model: Denoising diffusion model\n",
    "            x: Clean input data\n",
    "            num_samples: How many times to compute ELBO, final\n",
    "                result is averaged over all ELBO samples\n",
    "            **kwargs: Can be time, latent etc. depending on a model\n",
    "        \"\"\"\n",
    "        elbo = 0\n",
    "\n",
    "        i = expand_to_x(torch.arange(self.num_steps), x).expand(-1, *x[...,:1].shape).contiguous()\n",
    "        alphas = expand_to_x(self.alphas, x)\n",
    "        betas = expand_to_x(self.betas, x)\n",
    "\n",
    "        xt, kwargs = expand_x_and_kwargs(x, kwargs, self.num_steps)\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            # Get diffused outputs\n",
    "            xt, _ = self.forward(x, i, **kwargs) # [num_steps, ..., dim]\n",
    "\n",
    "            # Output predicted noise\n",
    "            epsilon = model(xt, i=i, **kwargs)\n",
    "\n",
    "            if L is not None:\n",
    "                epsilon = L @ epsilon\n",
    "\n",
    "            # p(x_{t-1} | p_t)\n",
    "            p_mu = get_p_mu(xt, betas, alphas, epsilon)\n",
    "            px = td.Independent(td.Normal(p_mu[1:], betas[1:].sqrt()), 1)\n",
    "\n",
    "            # p(x_0 | x_1)\n",
    "            log_prob_x0_x1 = td.Independent(td.Normal(p_mu[0], betas[0].sqrt()), 1).log_prob(x)\n",
    "            assert log_prob_x0_x1.shape == x.shape[:-1]\n",
    "\n",
    "            # q(x_{t-1} | x_0, x_t), t > 1\n",
    "            qx = get_qx(x.unsqueeze(0), xt[1:], alphas[1:], alphas[:-1], betas[1:])\n",
    "\n",
    "            # KL[q(x_{t-1} | p_t) || p(x_{t-1} | p_t)]\n",
    "            kl_q_p = td.kl_divergence(qx, px).sum(0)\n",
    "            assert kl_q_p.shape == x.shape[:-1]\n",
    "\n",
    "            # ELBO\n",
    "            elbo_contribution = (log_prob_x0_x1 - kl_q_p) / num_samples\n",
    "            elbo += elbo_contribution\n",
    "\n",
    "        elbo = reduce_elbo(elbo, x)\n",
    "        return elbo\n",
    "\n",
    "    def _elbo_sequential(\n",
    "        self,\n",
    "        model: Callable,\n",
    "        x: TensorType[..., 'dim'],\n",
    "        L: TensorType[..., 'seq_len', 'seq_len'],\n",
    "        num_samples: int = 1,\n",
    "        **kwargs,\n",
    "    ) -> TensorType[..., 1]:\n",
    "        \"\"\"\n",
    "        Computes ELBO as a sum of diffusion steps - sequentially.\n",
    "\n",
    "        Args:\n",
    "            model: Denoising diffusion model\n",
    "            x: Clean input data\n",
    "            num_samples: How many times to compute ELBO, final\n",
    "                result is averaged over all ELBO samples\n",
    "            **kwargs: Can be time, latent etc. depending on a model\n",
    "        \"\"\"\n",
    "        elbo = 0\n",
    "\n",
    "        x, kwargs = expand_x_and_kwargs(x, kwargs, num_samples)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            # Prepare variables\n",
    "            beta = self.betas[i].to(x)\n",
    "            alpha = self.alphas[i].to(x)\n",
    "            step = torch.Tensor([i]).expand_as(x[...,:1]).to(x)\n",
    "\n",
    "            # Diffuse and predict noise\n",
    "            xt, _ = self.forward(x, i=step, **kwargs)\n",
    "            epsilon = model(xt, i=step, **kwargs)\n",
    "\n",
    "            if L is not None:\n",
    "                epsilon = L @ epsilon\n",
    "\n",
    "            assert xt.shape == x.shape == epsilon.shape\n",
    "\n",
    "            # p(x_{t-1} | p_t)\n",
    "            p_mu = get_p_mu(xt, beta, alpha, epsilon)\n",
    "            px = td.Independent(td.Normal(p_mu, beta.sqrt()), 1)\n",
    "\n",
    "            if i == 0:\n",
    "                elbo = elbo + px.log_prob(x).mean(0)\n",
    "            else:\n",
    "                prev_alpha = self.alphas[i - 1]\n",
    "\n",
    "                # q(x_{t-1} | x_0, x_t), t > 1\n",
    "                qx = get_qx(x, xt, alpha, prev_alpha, beta)\n",
    "\n",
    "                # KL[q(x_{t-1} | p_t) || p(x_{t-1} | p_t)]\n",
    "                kl = td.kl_divergence(qx, px).mean(0)\n",
    "                elbo = elbo - kl\n",
    "\n",
    "        elbo = reduce_elbo(elbo, x)\n",
    "        return elbo\n",
    "\n",
    "\n",
    "class GaussianDiffusion(DiscreteDiffusion):\n",
    "    \"\"\" Discrete diffusion with Gaussian noise \"\"\"\n",
    "    def __init__(self, dim: int, num_steps: int, beta_fn: Callable, **kwargs):\n",
    "        super().__init__(dim, num_steps, beta_fn, noise_fn=Normal(dim), **kwargs)\n",
    "\n",
    "\n",
    "class OUDiffusion(DiscreteDiffusion):\n",
    "    \"\"\" Discrete diffusion with noise coming from an OU process \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_steps: int,\n",
    "        beta_fn: Callable,\n",
    "        predict_gaussian_noise: bool,\n",
    "        theta: float = 0.5,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim=dim,\n",
    "            num_steps=num_steps,\n",
    "            beta_fn=beta_fn,\n",
    "            noise_fn=OrnsteinUhlenbeck(dim, theta=theta),\n",
    "            is_time_series=True,\n",
    "            predict_gaussian_noise=predict_gaussian_noise,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "class GPDiffusion(DiscreteDiffusion):\n",
    "    \"\"\" Discrete diffusion with noise coming from a Gaussian process \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_steps: int,\n",
    "        beta_fn: Callable,\n",
    "        predict_gaussian_noise: bool,\n",
    "        sigma: float = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim=dim,\n",
    "            num_steps=num_steps,\n",
    "            beta_fn=beta_fn,\n",
    "            noise_fn=GaussianProcess(dim, sigma=sigma),\n",
    "            is_time_series=True,\n",
    "            predict_gaussian_noise=predict_gaussian_noise,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "def expand_to_x(inputs, x):\n",
    "    return inputs.view(-1, *(1,) * len(x.shape)).to(x)\n",
    "\n",
    "def expand_x_and_kwargs(x, kwargs, N):\n",
    "    # Expand dimensions\n",
    "    x = x.unsqueeze(0).repeat_interleave(N, dim=0)\n",
    "\n",
    "    # A hacky solution to repeat dimensions in all kwargs (latent, t, etc.)\n",
    "    for key, value in kwargs.items():\n",
    "        if torch.is_tensor(value):\n",
    "            kwargs[key] = value.unsqueeze(0).repeat_interleave(N, dim=0)\n",
    "\n",
    "    return x, kwargs\n",
    "\n",
    "def reduce_elbo(\n",
    "    elbo: TensorType['batch', Any],\n",
    "    x: TensorType[Any],\n",
    ") -> TensorType['batch', 1]:\n",
    "    # Reduce ELBO over all but batch dimension: (B, ...) -> (B,)\n",
    "    elbo = elbo.view(elbo.shape[0], -1).sum(1)\n",
    "\n",
    "    if len(x.shape) > 2:\n",
    "        elbo = elbo / x.shape[-2]\n",
    "\n",
    "    return elbo.unsqueeze(1)\n",
    "\n",
    "def get_p_mu(xt, beta, alpha, epsilon):\n",
    "    mu = 1 / (1 - beta).sqrt() * (xt - beta / (1 - alpha).sqrt() * epsilon)\n",
    "    return mu\n",
    "\n",
    "def get_qx(x, xt, alpha, prev_alpha, beta):\n",
    "    q_mu_1 = torch.sqrt(prev_alpha) * beta / (1 - alpha) * x\n",
    "    q_mu_2 = torch.sqrt(1 - beta) * (1 - prev_alpha) / (1 - alpha) * xt\n",
    "    q_mu = q_mu_1 + q_mu_2\n",
    "\n",
    "    q_sigma = beta * (1 - prev_alpha) / (1 - alpha)\n",
    "\n",
    "    qx = td.Independent(td.Normal(q_mu, q_sigma.expand_as(q_mu).sqrt()), 1)\n",
    "    return qx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DiffusionEmbeddingET(nn.Module):\n",
    "    def __init__(self, dim, proj_dim, max_steps=500):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\n",
    "            \"embedding\", self._build_embedding(dim, max_steps), persistent=False\n",
    "        )\n",
    "        self.projection1 = nn.Linear(dim * 2, proj_dim)\n",
    "        self.projection2 = nn.Linear(proj_dim, proj_dim)\n",
    "\n",
    "    def forward(self, diffusion_step):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, dim, max_steps):\n",
    "        steps = torch.arange(max_steps).unsqueeze(1)  # [T,1]\n",
    "        dims = torch.arange(dim).unsqueeze(0)  # [1,dim]\n",
    "        table = steps * 10.0 ** (dims * 4.0 / dim)  # [T,dim]\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)\n",
    "        return table\n",
    "\n",
    "\n",
    "class ResidualBlockET(nn.Module):\n",
    "    def __init__(self, hidden_size, residual_channels, dilation):\n",
    "        super().__init__()\n",
    "        self.dilated_conv = nn.Conv1d(\n",
    "            residual_channels,\n",
    "            2 * residual_channels,\n",
    "            3,\n",
    "            padding=dilation,\n",
    "            dilation=dilation,\n",
    "            padding_mode=\"circular\",\n",
    "        )\n",
    "        self.diffusion_projection = nn.Linear(hidden_size, residual_channels)\n",
    "        self.conditioner_projection = nn.Conv1d(\n",
    "            1, 2 * residual_channels, 1, padding=2, padding_mode=\"circular\"\n",
    "        )\n",
    "        self.output_projection = nn.Conv1d(residual_channels, 2 * residual_channels, 1)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.conditioner_projection.weight)\n",
    "        nn.init.kaiming_normal_(self.output_projection.weight)\n",
    "\n",
    "    def forward(self, x, conditioner, diffusion_step):\n",
    "        diffusion_step = self.diffusion_projection(diffusion_step).unsqueeze(-1)\n",
    "        conditioner = self.conditioner_projection(conditioner)\n",
    "\n",
    "        y = x + diffusion_step\n",
    "        y = self.dilated_conv(y) + conditioner\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)\n",
    "\n",
    "        y = self.output_projection(y)\n",
    "        y = F.leaky_relu(y, 0.4)\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        return (x + residual) / math.sqrt(2.0), skip\n",
    "\n",
    "\n",
    "class CondUpsamplerET(nn.Module):\n",
    "    def __init__(self, cond_length, target_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(cond_length, target_dim // 2)\n",
    "        self.linear2 = nn.Linear(target_dim // 2, target_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.leaky_relu(x, 0.4)\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x, 0.4)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EpsilonTheta(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_dim,\n",
    "        cond_length,\n",
    "        time_emb_dim=16,\n",
    "        residual_layers=8,\n",
    "        residual_channels=8,\n",
    "        dilation_cycle_length=2,\n",
    "        residual_hidden=64,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_projection = nn.Conv1d(\n",
    "            1, residual_channels, 1, padding=2, padding_mode=\"circular\"\n",
    "        )\n",
    "        self.diffusion_embedding = DiffusionEmbeddingET(\n",
    "            time_emb_dim, proj_dim=residual_hidden\n",
    "        )\n",
    "        self.cond_upsampler = CondUpsamplerET(\n",
    "            target_dim=target_dim, cond_length=cond_length\n",
    "        )\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "            [\n",
    "                ResidualBlockET(\n",
    "                    residual_channels=residual_channels,\n",
    "                    dilation=2 ** (i % dilation_cycle_length),\n",
    "                    hidden_size=residual_hidden,\n",
    "                )\n",
    "                for i in range(residual_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.skip_projection = nn.Conv1d(residual_channels, residual_channels, 3)\n",
    "        self.output_projection = nn.Conv1d(residual_channels, 1, 3)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.input_projection.weight)\n",
    "        nn.init.kaiming_normal_(self.skip_projection.weight)\n",
    "        nn.init.zeros_(self.output_projection.weight)\n",
    "\n",
    "    def forward(self, inputs, time, cond):\n",
    "        x = self.input_projection(inputs)\n",
    "        x = F.leaky_relu(x, 0.4)\n",
    "\n",
    "        diffusion_step = self.diffusion_embedding(time)\n",
    "        cond_up = self.cond_upsampler(cond)\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, cond_up, diffusion_step)\n",
    "            skip.append(skip_connection)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip), dim=0) / math.sqrt(len(self.residual_layers))\n",
    "        x = self.skip_projection(x)\n",
    "        x = F.leaky_relu(x, 0.4)\n",
    "        x = self.output_projection(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\" Dot notation access to dict attributes \"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtyping import TensorType\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pts.model import weighted_average\n",
    "from pts.model.time_grad import TimeGradTrainingNetwork, TimeGradPredictionNetwork\n",
    "from pts.model.time_grad.epsilon_theta import DiffusionEmbedding\n",
    "\n",
    "\n",
    "class TimeGradTrainingNetwork_AutoregressiveOld(TimeGradTrainingNetwork):\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs.pop('time_feat_dim')\n",
    "        kwargs.pop('noise')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class TimeGradPredictionNetwork_AutoregressiveOld(TimeGradPredictionNetwork):\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs.pop('time_feat_dim')\n",
    "        kwargs.pop('noise')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "class DenoiseWrapper(nn.Module):\n",
    "    def __init__(self, denoise_fn, target_dim, time_input):\n",
    "        super().__init__()\n",
    "        self.denoise_fn = denoise_fn\n",
    "        self.time_input = time_input\n",
    "        if self.time_input:\n",
    "            self.time_embedding = DiffusionEmbedding(dim=target_dim, proj_dim=target_dim, max_steps=100)\n",
    "\n",
    "    def forward(self, x, t=None, i=None, latent=None, **kwargs):\n",
    "        shape = x.shape\n",
    "\n",
    "        if self.time_input:\n",
    "            x = x + self.time_embedding(t.squeeze(-1).long())\n",
    "\n",
    "        x = x.view(-1, 1, x.shape[-1])\n",
    "        i = i.view(-1).long()\n",
    "        latent = latent.reshape(-1, 1, latent.shape[-1])\n",
    "\n",
    "        y = self.denoise_fn(x, i, latent)\n",
    "        y = y.view(*shape)\n",
    "        return y\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#### TimeGrad RNN encoder --> prediction all at once using time positional encoding\n",
    "#### using the past prediction window sized RNN context\n",
    "################################################################################################\n",
    "class TimeGradTrainingNetwork_All(TimeGradTrainingNetwork):\n",
    "    def __init__(self, **kwargs):\n",
    "        args = dotdict(kwargs)\n",
    "        self.noise = args.noise\n",
    "\n",
    "        kwargs.pop('time_feat_dim')\n",
    "        kwargs.pop('noise')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.time_input = (self.noise != 'normal')\n",
    "        self.rnn_state_proj = nn.Linear(args.num_cells, args.conditioning_length)\n",
    "\n",
    "        if self.noise == 'normal':\n",
    "            diffusion = GaussianDiffusion\n",
    "        elif self.noise == 'ou':\n",
    "            diffusion = OUDiffusion\n",
    "        elif self.noise == 'gp':\n",
    "            diffusion = GPDiffusion\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.diffusion = diffusion(args.target_dim, args.diff_steps, BetaLinear(1e-4, args.beta_end), sigma=0.05, predict_gaussian_noise=True)\n",
    "\n",
    "        denoise_fn = EpsilonTheta(\n",
    "            target_dim=args.target_dim,\n",
    "            cond_length=args.conditioning_length,\n",
    "            residual_layers=args.residual_layers,\n",
    "            residual_channels=args.residual_channels,\n",
    "            dilation_cycle_length=args.dilation_cycle_length,\n",
    "        )\n",
    "\n",
    "        self.denoise_fn = DenoiseWrapper(denoise_fn, args.target_dim, self.time_input)\n",
    "\n",
    "    def get_rnn_state(self, **kwargs):\n",
    "        rnn_outputs, _, scale, _, _ = self.unroll_encoder(**kwargs)\n",
    "        rnn_outputs = self.rnn_state_proj(rnn_outputs)\n",
    "        return rnn_outputs, scale\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        target_dimension_indicator: torch.Tensor,\n",
    "        past_time_feat: torch.Tensor,\n",
    "        past_target_cdf: torch.Tensor,\n",
    "        past_observed_values: torch.Tensor,\n",
    "        past_is_pad: torch.Tensor,\n",
    "        future_time_feat: torch.Tensor,\n",
    "        future_target_cdf: torch.Tensor,\n",
    "        future_observed_values: torch.Tensor,\n",
    "    ) -> TensorType[()]:\n",
    "\n",
    "        latent, scale = self.get_rnn_state(\n",
    "            past_time_feat=past_time_feat,\n",
    "            past_target_cdf=past_target_cdf,\n",
    "            past_observed_values=past_observed_values,\n",
    "            past_is_pad=past_is_pad,\n",
    "            future_time_feat=future_time_feat,\n",
    "            future_target_cdf=None,\n",
    "            target_dimension_indicator=target_dimension_indicator,\n",
    "        )\n",
    "\n",
    "        mean = past_target_cdf[...,-self.prediction_length:,:].mean(1, keepdim=True)\n",
    "        std = past_target_cdf[...,-self.prediction_length:,:].std(1, keepdim=True).clamp(1e-4)\n",
    "\n",
    "        # target = future_target_cdf[...,-self.prediction_length:,:] / scale\n",
    "        target = (future_target_cdf[...,-self.prediction_length:,:] - mean) / std\n",
    "        # target = (future_target_cdf[...,-self.prediction_length:,:] - past_target_cdf[...,-1:,:] - mean) / std\n",
    "        # target = (future_target_cdf[...,-self.prediction_length:,:] - past_target_cdf[...,-1:,:]) / scale\n",
    "\n",
    "        t = torch.arange(self.prediction_length).view(1, -1, 1).repeat(target.shape[0], 1, 1).to(target)\n",
    "        loss = self.diffusion.get_loss(self.denoise_fn, target, t=t, latent=latent, future_time_feat=future_time_feat)\n",
    "\n",
    "        loss_weights, _ = future_observed_values.min(dim=-1, keepdim=True)\n",
    "        loss = weighted_average(loss, weights=loss_weights, dim=1)\n",
    "\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class TimeGradPredictionNetwork_All(TimeGradTrainingNetwork_All):\n",
    "    def __init__(self, num_parallel_samples: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_samples = num_parallel_samples\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        target_dimension_indicator: torch.Tensor,\n",
    "        past_time_feat: torch.Tensor,\n",
    "        past_target_cdf: torch.Tensor,\n",
    "        past_observed_values: torch.Tensor,\n",
    "        past_is_pad: torch.Tensor,\n",
    "        future_time_feat: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        mean = past_target_cdf[...,-self.prediction_length:,:].mean(1, keepdim=True)\n",
    "        std = past_target_cdf[...,-self.prediction_length:,:].std(1, keepdim=True).clamp(1e-4)\n",
    "\n",
    "        latent, scale = self.get_rnn_state(\n",
    "            past_time_feat=past_time_feat,\n",
    "            past_target_cdf=past_target_cdf,\n",
    "            past_observed_values=past_observed_values,\n",
    "            past_is_pad=past_is_pad,\n",
    "            future_time_feat=future_time_feat,\n",
    "            future_target_cdf=None,\n",
    "            target_dimension_indicator=target_dimension_indicator,\n",
    "        )\n",
    "\n",
    "        num_samples = (self.num_samples * latent.shape[0], *latent.shape[1:-1])\n",
    "        latent = latent.repeat_interleave(self.num_samples, dim=0)\n",
    "        future_time_feat = future_time_feat.repeat_interleave(self.num_samples, dim=0)\n",
    "\n",
    "        t = torch.arange(self.prediction_length).view(*(1,) * len(latent.shape[:-3]), -1, 1)\n",
    "        t = t.expand_as(latent[...,:1]).to(latent)\n",
    "\n",
    "        samples = self.diffusion.sample(\n",
    "            self.denoise_fn,\n",
    "            num_samples=num_samples,\n",
    "            latent=latent,\n",
    "            t=t,\n",
    "            future_time_feat=future_time_feat,\n",
    "            device=latent.device,\n",
    "        )\n",
    "\n",
    "        samples = samples.unflatten(0, (-1, self.num_samples))\n",
    "        samples = samples * std.unsqueeze(1) + mean.unsqueeze(1)\n",
    "        # samples = samples * scale.unsqueeze(1)\n",
    "        # samples = samples + past_target_cdf[...,-1:,:].unsqueeze(1)\n",
    "        return samples\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#### TimeGrad Autoregressive -> predicts one by one\n",
    "################################################################################################\n",
    "class TimeGradTrainingNetwork_Autoregressive(TimeGradTrainingNetwork_All):\n",
    "    def forward(\n",
    "        self,\n",
    "        target_dimension_indicator: torch.Tensor,\n",
    "        past_time_feat: torch.Tensor,\n",
    "        past_target_cdf: torch.Tensor,\n",
    "        past_observed_values: torch.Tensor,\n",
    "        past_is_pad: torch.Tensor,\n",
    "        future_time_feat: torch.Tensor,\n",
    "        future_target_cdf: torch.Tensor,\n",
    "        future_observed_values: torch.Tensor,\n",
    "    ) -> TensorType[()]:\n",
    "\n",
    "        latent, scale = self.get_rnn_state(\n",
    "            past_time_feat=past_time_feat,\n",
    "            past_target_cdf=past_target_cdf,\n",
    "            past_observed_values=past_observed_values,\n",
    "            past_is_pad=past_is_pad,\n",
    "            future_time_feat=future_time_feat,\n",
    "            future_target_cdf=future_target_cdf,\n",
    "            target_dimension_indicator=target_dimension_indicator,\n",
    "        )\n",
    "\n",
    "        target = torch.cat([past_target_cdf[...,-self.context_length:,:], future_target_cdf], 1)\n",
    "        target = target / scale\n",
    "\n",
    "        loss = self.diffusion.get_loss(self.denoise_fn, target, latent=latent, future_time_feat=future_time_feat)\n",
    "\n",
    "        past_observed_values = torch.min(past_observed_values, 1 - past_is_pad.unsqueeze(-1))\n",
    "        observed_values = torch.cat((past_observed_values[:, -self.context_length:, ...], future_observed_values), dim=1)\n",
    "        loss_weights, _ = observed_values.min(dim=-1, keepdim=True)\n",
    "\n",
    "        loss = weighted_average(loss, weights=loss_weights, dim=1)\n",
    "\n",
    "        return loss.mean()\n",
    "\n",
    "class TimeGradPredictionNetwork_Autoregressive(TimeGradTrainingNetwork_Autoregressive):\n",
    "    def __init__(self, num_parallel_samples: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_samples = num_parallel_samples\n",
    "        self.shifted_lags = [l - 1 for l in self.lags_seq]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(\n",
    "        self,\n",
    "        target_dimension_indicator: torch.Tensor,\n",
    "        past_time_feat: torch.Tensor,\n",
    "        past_target_cdf: torch.Tensor,\n",
    "        past_observed_values: torch.Tensor,\n",
    "        past_is_pad: torch.Tensor,\n",
    "        future_time_feat: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        past_observed_values = torch.min(past_observed_values, 1 - past_is_pad.unsqueeze(-1))\n",
    "\n",
    "        past_time_feat = past_time_feat.repeat_interleave(self.num_samples, dim=0)\n",
    "        past_target_cdf = past_target_cdf.repeat_interleave(self.num_samples, dim=0)\n",
    "        past_observed_values = past_observed_values.repeat_interleave(self.num_samples, dim=0)\n",
    "        past_is_pad = past_is_pad.repeat_interleave(self.num_samples, dim=0)\n",
    "        future_time_feat = future_time_feat.repeat_interleave(self.num_samples, dim=0)\n",
    "        target_dimension_indicator = target_dimension_indicator.repeat_interleave(self.num_samples, dim=0)\n",
    "\n",
    "        _, begin_states, scale, _, _ = self.unroll_encoder(\n",
    "            past_time_feat=past_time_feat,\n",
    "            past_target_cdf=past_target_cdf,\n",
    "            past_observed_values=past_observed_values,\n",
    "            past_is_pad=past_is_pad,\n",
    "            future_time_feat=future_time_feat,\n",
    "            future_target_cdf=None,\n",
    "            target_dimension_indicator=target_dimension_indicator,\n",
    "        )\n",
    "\n",
    "        samples = []\n",
    "        for i in range(self.prediction_length):\n",
    "            lags = self.get_lagged_subsequences(\n",
    "                sequence=past_target_cdf,\n",
    "                sequence_length=self.history_length + i,\n",
    "                indices=self.shifted_lags,\n",
    "                subsequences_length=1,\n",
    "            )\n",
    "\n",
    "            latent, begin_states, _, _ = self.unroll(\n",
    "                begin_state=begin_states,\n",
    "                lags=lags,\n",
    "                scale=scale,\n",
    "                time_feat=future_time_feat[:, i : i + 1],\n",
    "                target_dimension_indicator=target_dimension_indicator,\n",
    "                unroll_length=1,\n",
    "            )\n",
    "            latent = self.rnn_state_proj(latent)\n",
    "\n",
    "            sample = self.diffusion.sample(\n",
    "                self.denoise_fn,\n",
    "                num_samples=latent.shape[:-1],\n",
    "                latent=latent,\n",
    "                device=latent.device,\n",
    "            )\n",
    "            sample = sample * scale\n",
    "\n",
    "            samples.append(sample)\n",
    "            past_target_cdf = torch.cat([past_target_cdf, sample], dim=1)\n",
    "\n",
    "        samples = torch.cat(samples, dim=1)\n",
    "        samples = samples.unflatten(0, (-1, self.num_samples))\n",
    "\n",
    "        return samples\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#### TimeGrad RNN encoder --> predicting all at once with RNN+TimeGrad decoder\n",
    "#### RNN initial state is the last state from the encoder\n",
    "################################################################################################\n",
    "class TimeGradTrainingNetwork_RNN(TimeGradTrainingNetwork_All):\n",
    "    def __init__(self, **kwargs):\n",
    "        args = dotdict(kwargs)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_rnn_layers = 2\n",
    "        self.proj_inputs = nn.Sequential(\n",
    "            nn.Linear(args.time_feat_dim , args.conditioning_length),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.conditioning_length , args.conditioning_length),\n",
    "        )\n",
    "        self.prediction_rnn = nn.GRU(args.conditioning_length, args.conditioning_length,\n",
    "            num_layers=self.num_rnn_layers, bidirectional=False, batch_first=True)\n",
    "\n",
    "    def get_rnn_state(self, **kwargs):\n",
    "        states, _, scale, _, _ = self.unroll_encoder(**kwargs)\n",
    "        states = self.rnn_state_proj(states)\n",
    "\n",
    "        states = states[...,-1,:].unsqueeze(0).repeat_interleave(self.num_rnn_layers, dim=0)\n",
    "\n",
    "        inputs = self.proj_inputs(kwargs['future_time_feat'])\n",
    "        out, _ = self.prediction_rnn(inputs, states)\n",
    "\n",
    "        return out, scale\n",
    "\n",
    "class TimeGradPredictionNetwork_RNN(TimeGradTrainingNetwork_RNN):\n",
    "    forward = TimeGradPredictionNetwork_All.forward\n",
    "\n",
    "    def __init__(self, num_parallel_samples: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_samples = num_parallel_samples\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#### TimeGrad RNN encoder --> predicting all at once with Transformer decoder+TimeGrad net\n",
    "################################################################################################\n",
    "class TimeGradTrainingNetwork_Transformer(TimeGradTrainingNetwork_All):\n",
    "    def __init__(self, **kwargs):\n",
    "        args = dotdict(kwargs)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.pos_enc = DiffusionEmbedding(dim=args.conditioning_length, proj_dim=args.conditioning_length, max_steps=100)\n",
    "        self.proj_time_feat = nn.Linear(args.time_feat_dim + args.conditioning_length, args.conditioning_length)\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(args.conditioning_length, nhead=1, dim_feedforward=args.conditioning_length, batch_first=True)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=2)\n",
    "\n",
    "    def get_rnn_state(self, **kwargs):\n",
    "        states, _, scale, _, _ = self.unroll_encoder(**kwargs)\n",
    "        states = self.rnn_state_proj(states)\n",
    "\n",
    "        t = torch.arange(self.prediction_length).view(1, -1).repeat(states.shape[0], 1).to(states)\n",
    "        t = self.pos_enc(t.long())\n",
    "\n",
    "        x = torch.cat([t, kwargs['future_time_feat']], -1)\n",
    "        x = self.proj_time_feat(x)\n",
    "        out = self.transformer_decoder(tgt=x, memory=states)\n",
    "        return out, scale\n",
    "\n",
    "class TimeGradPredictionNetwork_Transformer(TimeGradTrainingNetwork_Transformer):\n",
    "    forward = TimeGradPredictionNetwork_All.forward\n",
    "\n",
    "    def __init__(self, num_parallel_samples: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_samples = num_parallel_samples\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#### TimeGrad RNN encoder --> predicting all at once with 2D conv similar to TimeGrad version\n",
    "################################################################################################\n",
    "class ResidualBlockTG(nn.Module):\n",
    "    def __init__(self, dim, hidden_size, residual_channels, dilation, padding_mode):\n",
    "        super().__init__()\n",
    "        self.step_projection = nn.Linear(hidden_size, residual_channels)\n",
    "        self.time_projection = nn.Linear(hidden_size, residual_channels)\n",
    "\n",
    "        self.x_step_proj = nn.Sequential(\n",
    "            nn.Conv2d(residual_channels, residual_channels, kernel_size=1, padding='same', padding_mode=padding_mode),\n",
    "            nn.LeakyReLU(0.4),\n",
    "        )\n",
    "        self.x_time_proj = nn.Sequential(\n",
    "            nn.Conv2d(residual_channels, residual_channels, kernel_size=1, padding='same', padding_mode=padding_mode),\n",
    "            nn.LeakyReLU(0.4),\n",
    "        )\n",
    "\n",
    "        self.latent_projection = nn.Conv2d(\n",
    "            1, 2 * residual_channels, kernel_size=1, padding='same', padding_mode=padding_mode,\n",
    "        )\n",
    "        self.dilated_conv = nn.Conv2d(\n",
    "            1 * residual_channels,\n",
    "            2 * residual_channels,\n",
    "            kernel_size=3,\n",
    "            dilation=dilation,\n",
    "            padding='same',\n",
    "            padding_mode=padding_mode,\n",
    "        )\n",
    "        self.output_projection = nn.Conv2d(\n",
    "            residual_channels, 2 * residual_channels, kernel_size=1, padding='same', padding_mode=padding_mode,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t=None, i=None, latent=None):\n",
    "        i = self.step_projection(i).transpose(-1, -2).unsqueeze(-1)\n",
    "        latent = self.latent_projection(latent.unsqueeze(1))\n",
    "\n",
    "        y = x + i\n",
    "        y = y + self.x_step_proj(y)\n",
    "\n",
    "        t = self.time_projection(t).transpose(-1, -2).unsqueeze(-1)\n",
    "        y = y + self.x_time_proj(y + t)\n",
    "\n",
    "        y = self.dilated_conv(y) + latent\n",
    "\n",
    "        gate, filter = y.chunk(2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)\n",
    "\n",
    "        y = self.output_projection(y)\n",
    "        y = F.leaky_relu(y, 0.4)\n",
    "\n",
    "        residual, skip = y.chunk(2, dim=1)\n",
    "        return (x + residual) / math.sqrt(2), skip\n",
    "\n",
    "class DenoisingModelTG(nn.Module):\n",
    "    def __init__(self, dim, residual_channels, latent_dim, residual_hidden, residual_layers, time_input, padding_mode='circular'):\n",
    "        super().__init__()\n",
    "        self.time_input = time_input\n",
    "\n",
    "        self.input_projection = nn.Conv2d(1, residual_channels, kernel_size=1, padding='same', padding_mode=padding_mode)\n",
    "        self.step_embedding = DiffusionEmbedding(residual_hidden, proj_dim=residual_hidden)\n",
    "        self.time_embedding = DiffusionEmbedding(residual_hidden, proj_dim=residual_hidden, max_steps=24)\n",
    "        self.latent_projection = nn.Sequential(\n",
    "            nn.Linear(latent_dim, dim // 2),\n",
    "            nn.LeakyReLU(0.4),\n",
    "            nn.Linear(dim // 2, dim),\n",
    "            nn.LeakyReLU(0.4),\n",
    "        )\n",
    "\n",
    "        self.residual_layers = nn.ModuleList([\n",
    "            ResidualBlockTG(dim, residual_hidden, residual_channels, dilation=2**(i % 2), padding_mode=padding_mode)\n",
    "            for i in range(residual_layers)\n",
    "        ])\n",
    "\n",
    "        self.skip_projection = nn.Conv2d(\n",
    "            residual_channels, residual_channels, kernel_size=3, padding='same', padding_mode=padding_mode,\n",
    "        )\n",
    "        self.output_projection = nn.Conv2d(\n",
    "            residual_channels, 1, kernel_size=3, padding='same', padding_mode=padding_mode,\n",
    "        )\n",
    "\n",
    "        self.time_proj = nn.Sequential(\n",
    "            nn.Linear(5, residual_hidden),\n",
    "            nn.LeakyReLU(0.4),\n",
    "            nn.Linear(residual_hidden, residual_hidden),\n",
    "            nn.LeakyReLU(0.4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t=None, i=None, latent=None, future_time_feat=None):\n",
    "        shape = x.shape\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.input_projection(x)\n",
    "        x = F.leaky_relu(x, 0.4)\n",
    "\n",
    "        i = self.step_embedding(i.squeeze(-1).long())\n",
    "        # if t is not None:\n",
    "        #     t = self.time_embedding(t.squeeze(-1).long())\n",
    "\n",
    "        t = self.time_proj(torch.cat([future_time_feat, t / t.max()], -1))\n",
    "\n",
    "        latent = self.latent_projection(latent)\n",
    "\n",
    "        skip_agg = 0\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip = layer(x, t=t, i=i, latent=latent)\n",
    "            skip_agg = skip_agg + skip\n",
    "\n",
    "        x = skip_agg / math.sqrt(len(self.residual_layers))\n",
    "        x = self.skip_projection(x)\n",
    "        x = F.leaky_relu(x, 0.4)\n",
    "        x = self.output_projection(x).squeeze(1)\n",
    "\n",
    "        x = x.view(*shape)\n",
    "        return x\n",
    "\n",
    "class TimeGradTrainingNetwork_CNN(TimeGradTrainingNetwork_All):\n",
    "    def __init__(self, **kwargs):\n",
    "        args = dotdict(kwargs)\n",
    "        super().__init__(**kwargs)\n",
    "        self.denoise_fn = DenoisingModelTG(\n",
    "            dim=args.target_dim,\n",
    "            residual_channels=args.residual_channels,\n",
    "            latent_dim=args.conditioning_length,\n",
    "            residual_hidden=args.conditioning_length,\n",
    "            time_input=self.time_input,\n",
    "            residual_layers=args.residual_layers,\n",
    "        )\n",
    "\n",
    "class TimeGradPredictionNetwork_CNN(TimeGradTrainingNetwork_CNN):\n",
    "    forward = TimeGradPredictionNetwork_All.forward\n",
    "\n",
    "    def __init__(self, num_parallel_samples: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_samples = num_parallel_samples\n",
    "        self.shifted_lags = [l - 1 for l in self.lags_seq]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotSupportedModelNoiseCombination(Exception):\n",
    "    pass\n",
    "\n",
    "def get_network(network,noise):\n",
    "    # Load model\n",
    "    if network == 'timegrad':\n",
    "        if noise != 'normal':\n",
    "            raise NotSupportedModelNoiseCombination\n",
    "        training_net, prediction_net = TimeGradTrainingNetwork_Autoregressive, TimeGradPredictionNetwork_Autoregressive\n",
    "    elif network == 'timegrad_old':\n",
    "        if noise != 'normal':\n",
    "            raise NotSupportedModelNoiseCombination\n",
    "        training_net, prediction_net = TimeGradTrainingNetwork_AutoregressiveOld, TimeGradPredictionNetwork_AutoregressiveOld\n",
    "    elif network == 'timegrad_all':\n",
    "        training_net, prediction_net = TimeGradTrainingNetwork_All, TimeGradPredictionNetwork_All\n",
    "    elif network == 'timegrad_rnn':\n",
    "        training_net, prediction_net = TimeGradTrainingNetwork_RNN, TimeGradPredictionNetwork_RNN\n",
    "    elif network == 'timegrad_transformer':\n",
    "        training_net, prediction_net = TimeGradTrainingNetwork_Transformer, TimeGradPredictionNetwork_Transformer\n",
    "    elif network == 'timegrad_cnn':\n",
    "        training_net, prediction_net = TimeGradTrainingNetwork_CNN, TimeGradPredictionNetwork_CNN\n",
    "    return training_net, prediction_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtyping import TensorType\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pts.modules import MeanScaler\n",
    "\n",
    "class ScoreTrainingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Score training network.\n",
    "\n",
    "    Args:\n",
    "        context_length: Size of history\n",
    "        prediction_length: Size of prediction\n",
    "        target_dim: Dimension of data\n",
    "        time_feat_dim: Dimension of covariates\n",
    "        conditioning_length: Hidden dimension\n",
    "        beta_end: Final diffusion scale\n",
    "        diff_steps: Number of diffusion steps\n",
    "        residual_layers: Number of residual layers\n",
    "        residual_channels: Number of residual channels\n",
    "        dilation_cycle_length: Dilation cycle length\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        context_length: int,\n",
    "        prediction_length: int,\n",
    "        target_dim: int,\n",
    "        time_feat_dim: int,\n",
    "        conditioning_length: int,\n",
    "        beta_end: float,\n",
    "        diff_steps: int,\n",
    "        residual_layers: int,\n",
    "        residual_channels: int,\n",
    "        dilation_cycle_length: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.context_length = context_length\n",
    "        self.prediction_length = prediction_length\n",
    "\n",
    "        # hidden_dim = conditioning_length\n",
    "        # self.context_rnn = nn.GRU(target_dim + time_feat_dim, hidden_dim, num_layers=2, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.diffusion = OUDiffusion(target_dim, BetaLinear(1e-4, beta_end), diff_steps)\n",
    "        self.denoise_fn = DenoisingModelTG(\n",
    "            dim=target_dim + time_feat_dim,\n",
    "            residual_channels=residual_channels,\n",
    "            latent_dim=conditioning_length,\n",
    "            residual_hidden=conditioning_length,\n",
    "        )\n",
    "\n",
    "        self.scaler = MeanScaler(keepdim=True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        target_dimension_indicator: TensorType['batch', 'dim'],\n",
    "        past_time_feat:             TensorType['batch', 'history_length', 'feat_dim'],\n",
    "        past_target_cdf:            TensorType['batch', 'history_length', 'dim'],\n",
    "        past_observed_values:       TensorType['batch', 'history_length', 'dim'],\n",
    "        past_is_pad:                TensorType['batch', 'history_length'],\n",
    "        future_time_feat:           TensorType['batch', 'prediction_length', 'feat_dim'],\n",
    "        future_target_cdf:          TensorType['batch', 'prediction_length', 'dim'],\n",
    "        future_observed_values:     TensorType['batch', 'prediction_length', 'dim'],\n",
    "    ) -> TensorType[()]:\n",
    "\n",
    "        past_time_feat = past_time_feat[...,-self.context_length:,:]\n",
    "        past_target_cdf = past_target_cdf[...,-self.context_length:,:]\n",
    "        past_observed_values = past_observed_values[...,-self.context_length:,:]\n",
    "        past_is_pad = past_is_pad[...,-self.context_length:]\n",
    "\n",
    "        past_observed_values = torch.min(past_observed_values, 1 - past_is_pad.unsqueeze(-1))\n",
    "        _, scale = self.scaler(past_target_cdf, past_observed_values)\n",
    "\n",
    "        history = past_target_cdf / scale\n",
    "        target = future_target_cdf / scale\n",
    "\n",
    "        t = torch.arange(self.prediction_length).view(1, -1, 1).repeat(target.shape[0], 1, 1).to(target)\n",
    "\n",
    "        loss = self.diffusion.get_loss(self.denoise_fn, target, t=t, history=history, covariates=future_time_feat)\n",
    "\n",
    "        loss_weights, _ = future_observed_values.min(dim=-1, keepdim=True)\n",
    "        loss = weighted_average(loss, weights=loss_weights, dim=1)\n",
    "\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class ScorePredictionNetwork(ScoreTrainingNetwork):\n",
    "    def __init__(self, num_parallel_samples: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_parallel_samples = num_parallel_samples\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        target_dimension_indicator: TensorType['batch', 'dim'],\n",
    "        past_time_feat:             TensorType['batch', 'history_length', 'feat_dim'],\n",
    "        past_target_cdf:            TensorType['batch', 'history_length', 'dim'],\n",
    "        past_observed_values:       TensorType['batch', 'history_length', 'dim'],\n",
    "        past_is_pad:                TensorType['batch', 'history_length'],\n",
    "        future_time_feat:           TensorType['batch', 'prediction_length', 'feat_dim'],\n",
    "    ) -> TensorType['batch', 'num_samples', 'prediction_length', 'dim']:\n",
    "\n",
    "        past_observed_values = torch.min(past_observed_values, 1 - past_is_pad.unsqueeze(-1))\n",
    "\n",
    "        rnn_states, scale = self.get_rnn_state(\n",
    "            past_time_feat=past_time_feat,\n",
    "            past_target_cdf=past_target_cdf,\n",
    "            past_observed_values=past_observed_values,\n",
    "            future_time_feat=future_time_feat,\n",
    "        )\n",
    "\n",
    "        t = torch.arange(self.prediction_length).view(1, -1, 1)\n",
    "        t = t.repeat(rnn_states.shape[0] * self.num_parallel_samples, 1, 1).to(rnn_states)\n",
    "\n",
    "        rnn_states = rnn_states.repeat_interleave(self.num_parallel_samples, dim=0)\n",
    "\n",
    "        samples = self.diffusion.sample(self.denoise_fn, t=t, latent=rnn_states)\n",
    "        samples = samples.unflatten(0, (-1, self.num_parallel_samples)) * scale.unsqueeze(1)\n",
    "\n",
    "        return samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def energy_score(forecast, target):\n",
    "    obs_dist = np.mean(np.linalg.norm((forecast - target), axis=-1))\n",
    "    pair_dist = np.mean(\n",
    "        np.linalg.norm(forecast[:, np.newaxis, ...] - forecast, axis=-1)\n",
    "    )\n",
    "    return obs_dist - pair_dist * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store arguments in a dictionary\n",
    "args = {\n",
    "    'seed': 1,\n",
    "    'dataset': \"electricity_nips\",\n",
    "    'network': \"timegrad_rnn\",  # Choose from ['timegrad', 'timegrad_old', 'timegrad_all', 'timegrad_rnn', 'timegrad_transformer', 'timegrad_cnn']\n",
    "    'noise': \"gp\",  # Choose from ['normal', 'ou', 'gp']\n",
    "    'diffusion_steps': 100,\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'batch_size': 64,\n",
    "    'num_cells': 100,\n",
    "    'hidden_dim': 100,\n",
    "    'residual_layers': 8\n",
    "}\n",
    "\n",
    "# Direct assignments for Jupyter notebook\n",
    "seed = 1\n",
    "dataset = \"electricity_nips\"\n",
    "network = \"timegrad_rnn\"  # Choose from ['timegrad', 'timegrad_old', 'timegrad_all', 'timegrad_rnn', 'timegrad_transformer', 'timegrad_cnn']\n",
    "noise = \"gp\"  # Choose from ['normal', 'ou', 'gp']\n",
    "diffusion_steps = 100\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "num_cells = 100\n",
    "hidden_dim = 100\n",
    "residual_layers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "covariance_dim = 4 if dataset != 'exchange_rate_nips' else -4\n",
    "\n",
    "# Load data\n",
    "dataset = get_dataset(dataset, regenerate=False)\n",
    "\n",
    "target_dim = int(dataset.metadata.feat_static_cat[0].cardinality)\n",
    "\n",
    "train_grouper = MultivariateGrouper(max_target_dim=min(2000, target_dim))\n",
    "test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test) / len(dataset.train)), max_target_dim=min(2000, target_dim))\n",
    "dataset_train = train_grouper(dataset.train)\n",
    "dataset_test = test_grouper(dataset.test)\n",
    "\n",
    "val_window = 20 * dataset.metadata.prediction_length\n",
    "dataset_train = list(dataset_train)\n",
    "dataset_val = []\n",
    "for i in range(len(dataset_train)):\n",
    "    x = deepcopy(dataset_train[i])\n",
    "    x['target'] = x['target'][:,-val_window:]\n",
    "    dataset_val.append(x)\n",
    "    dataset_train[i]['target'] = dataset_train[i]['target'][:,:-val_window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 5353)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0][\"target\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 480)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val[0][\"target\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_net, prediction_net = get_network(network,noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ScoreEstimator(\n",
    "    training_net=training_net,\n",
    "    prediction_net=prediction_net,\n",
    "    noise=noise,\n",
    "    target_dim=target_dim,\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=dataset.metadata.prediction_length,\n",
    "    cell_type='GRU',\n",
    "    num_cells=num_cells,\n",
    "    hidden_dim=hidden_dim,\n",
    "    residual_layers=residual_layers,\n",
    "    input_size=target_dim * 4 + covariance_dim,\n",
    "    freq=dataset.metadata.freq,\n",
    "    loss_type='l2',\n",
    "    scaling=True,\n",
    "    diff_steps=diffusion_steps,\n",
    "    beta_end=20 / diffusion_steps,\n",
    "    beta_schedule='linear',\n",
    "    num_parallel_samples=100,\n",
    "    pick_incomplete=True,\n",
    "    trainer=TrainerForecasting(\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        num_batches_per_epoch=100,\n",
    "        batch_size=batch_size,\n",
    "        patience=10,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# predictor = estimator.train(dataset_train, dataset_val, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader Outside GluonEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom typing import NamedTuple, Optional\\nfrom functools import partial\\n\\nimport numpy as np\\n\\nimport torch\\nimport torch.nn as nn\\nfrom torch.utils import data\\nfrom torch.utils.data import DataLoader\\n\\nfrom gluonts.env import env\\nfrom gluonts.core.component import validated\\nfrom gluonts.dataset.common import Dataset\\nfrom gluonts.model.estimator import Estimator\\nfrom gluonts.torch.model.predictor import PyTorchPredictor\\nfrom gluonts.transform import SelectFields, Transformation\\nfrom gluonts.itertools import maybe_len\\n\\nfrom pts import Trainer\\nfrom pts.model import get_module_forward_input_names\\nfrom pts.dataset.loader import TransformedIterableDataset\\n\\ndef train_model(\\n        self,\\n        training_data: Dataset,\\n        validation_data: Optional[Dataset] = None,\\n        num_workers: int = 0,\\n        prefetch_factor: int = 2,\\n        shuffle_buffer_length: Optional[int] = None,\\n        cache_data: bool = False,\\n        **kwargs,\\n    ):\\n        transformation = self.create_transformation()\\n\\n        trained_net = self.create_training_network(self.trainer.device)\\n\\n        input_names = get_module_forward_input_names(trained_net)\\n\\n        with env._let(max_idle_transforms=maybe_len(training_data) or 0):\\n            training_instance_splitter = self.create_instance_splitter(\"training\")\\n        training_iter_dataset = TransformedIterableDataset(\\n            dataset=training_data,\\n            transform=transformation\\n            + training_instance_splitter\\n            + SelectFields(input_names),\\n            is_train=True,\\n            shuffle_buffer_length=shuffle_buffer_length,\\n            cache_data=cache_data,\\n        )\\n\\n        if validation_data is not None:\\n            with env._let(max_idle_transforms=maybe_len(validation_data) or 0):\\n                validation_instance_splitter = self.create_instance_splitter(\"validation\")\\n            validation_iter_dataset = TransformedIterableDataset(\\n                dataset=validation_data,\\n                transform=transformation\\n                + validation_instance_splitter\\n                + SelectFields(input_names),\\n                is_train=True,\\n                cache_data=cache_data,\\n            )\\n        return training_iter_dataset, validation_iter_dataset\\n        \\nfrom gluonts.env import env\\nfrom gluonts.dataset.common import Dataset\\nfrom typing import NamedTuple, Optional\\nfrom gluonts.core.component import validated\\nfrom gluonts.model.estimator import Estimator\\nfrom gluonts.torch.model.predictor import PyTorchPredictor\\nfrom gluonts.transform import SelectFields, Transformation\\nfrom gluonts.itertools import maybe_len\\n\\nlags_seq = None\\ntime_features = None\\n\\ntraining_net=training_net\\nprediction_net=prediction_net\\nnoise=noise\\ntarget_dim=target_dim\\nprediction_length=dataset.metadata.prediction_length\\ncontext_length=dataset.metadata.prediction_length\\ncell_type=\\'GRU\\'\\nnum_cells=num_cells\\nhidden_dim=hidden_dim\\nresidual_layers=residual_layers\\ninput_size=target_dim * 4 + covariance_dim\\nfreq=dataset.metadata.freq\\nloss_type=\\'l2\\'\\nscaling=True\\ndiff_steps=diffusion_steps\\nbeta_end=20 / diffusion_steps\\nbeta_schedule=\\'linear\\'\\nnum_parallel_samples=100\\npick_incomplete=True\\n\\nclass TrainOutput(NamedTuple):\\n    transformation: Transformation\\n    trained_net: nn.Module\\n    predictor: PyTorchPredictor\\n\\ndef create_transformation() -> Transformation:\\n    return Chain(\\n        [\\n            AsNumpyArray(\\n                field=FieldName.TARGET,\\n                expected_ndim=2,\\n            ),\\n            # maps the target to (1, T)\\n            # if the target data is uni dimensional\\n            ExpandDimArray(\\n                field=FieldName.TARGET,\\n                axis=None,\\n            ),\\n            AddObservedValuesIndicator(\\n                target_field=FieldName.TARGET,\\n                output_field=FieldName.OBSERVED_VALUES,\\n            ),\\n            AddTimeFeatures(\\n                start_field=FieldName.START,\\n                target_field=FieldName.TARGET,\\n                output_field=FieldName.FEAT_TIME,\\n                time_features=time_features,\\n                pred_length=prediction_length,\\n            ),\\n            VstackFeatures(\\n                output_field=FieldName.FEAT_TIME,\\n                input_fields=[FieldName.FEAT_TIME],\\n            ),\\n            SetFieldIfNotPresent(field=FieldName.FEAT_STATIC_CAT, value=[0]),\\n            TargetDimIndicator(\\n                field_name=\"target_dimension_indicator\",\\n                target_field=FieldName.TARGET,\\n            ),\\n            AsNumpyArray(field=FieldName.FEAT_STATIC_CAT, expected_ndim=1),\\n        ]\\n    )\\n\\ndef create_instance_splitter(train_sampler,validation_sampler,mode: str):\\n    assert mode in [\"training\", \"validation\", \"test\"]\\n\\n    instance_sampler = {\\n        \"training\": train_sampler,\\n        \"validation\": validation_sampler,\\n        \"test\": TestSplitSampler(),\\n    }[mode]\\n\\n    return InstanceSplitter(\\n        target_field=FieldName.TARGET,\\n        is_pad_field=FieldName.IS_PAD,\\n        start_field=FieldName.START,\\n        forecast_start_field=FieldName.FORECAST_START,\\n        instance_sampler=instance_sampler,\\n        past_length=history_length,\\n        future_length=prediction_length,\\n        time_series_fields=[\\n            FieldName.FEAT_TIME,\\n            FieldName.OBSERVED_VALUES,\\n        ],\\n    ) + (\\n        RenameFields(\\n            {\\n                f\"past_{FieldName.TARGET}\": f\"past_{FieldName.TARGET}_cdf\",\\n                f\"future_{FieldName.TARGET}\": f\"future_{FieldName.TARGET}_cdf\",\\n            }\\n        )\\n    )\\n\\n\\ndef create_training_network(self, training_net, device: torch.device):\\n    return training_net(\\n        noise=self.noise,\\n        input_size=self.input_size,\\n        target_dim=self.target_dim,\\n        num_layers=self.num_layers,\\n        num_cells=self.num_cells,\\n        cell_type=self.cell_type,\\n        history_length=self.history_length,\\n        context_length=self.context_length,\\n        prediction_length=self.prediction_length,\\n        dropout_rate=self.dropout_rate,\\n        cardinality=self.cardinality,\\n        embedding_dimension=self.embedding_dimension,\\n        diff_steps=self.diff_steps,\\n        loss_type=self.loss_type,\\n        beta_end=self.beta_end,\\n        beta_schedule=self.beta_schedule,\\n        residual_layers=self.residual_layers,\\n        residual_channels=self.residual_channels,\\n        dilation_cycle_length=self.dilation_cycle_length,\\n        lags_seq=self.lags_seq,\\n        scaling=self.scaling,\\n        conditioning_length=self.conditioning_length,\\n        time_feat_dim=self.time_feat_dim,\\n    ).to(device)\\n\\nlags_seq = (\\n    lags_seq\\n    if lags_seq is not None\\n    else lags_for_fourier_time_features_from_frequency(freq_str=freq)\\n)\\n\\ntime_features = (\\n    time_features\\n    if time_features is not None\\n    else fourier_time_features_from_frequency(freq)\\n)\\n\\nhistory_length = context_length + max(lags_seq)\\npick_incomplete = pick_incomplete\\nscaling = scaling\\n\\ntrain_sampler = ExpectedNumInstanceSampler(\\n    num_instances=1.0,\\n    min_past=0 if pick_incomplete else history_length,\\n    min_future=prediction_length,\\n)\\n\\nvalidation_sampler = ValidationSplitSampler(\\n    min_past=0 if pick_incomplete else history_length,\\n    min_future=prediction_length,\\n) \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import NamedTuple, Optional\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gluonts.env import env\n",
    "from gluonts.core.component import validated\n",
    "from gluonts.dataset.common import Dataset\n",
    "from gluonts.model.estimator import Estimator\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "from gluonts.transform import SelectFields, Transformation\n",
    "from gluonts.itertools import maybe_len\n",
    "\n",
    "from pts import Trainer\n",
    "from pts.model import get_module_forward_input_names\n",
    "from pts.dataset.loader import TransformedIterableDataset\n",
    "\n",
    "\"\"\"\n",
    "from typing import NamedTuple, Optional\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gluonts.env import env\n",
    "from gluonts.core.component import validated\n",
    "from gluonts.dataset.common import Dataset\n",
    "from gluonts.model.estimator import Estimator\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "from gluonts.transform import SelectFields, Transformation\n",
    "from gluonts.itertools import maybe_len\n",
    "\n",
    "from pts import Trainer\n",
    "from pts.model import get_module_forward_input_names\n",
    "from pts.dataset.loader import TransformedIterableDataset\n",
    "\n",
    "def train_model(\n",
    "        self,\n",
    "        training_data: Dataset,\n",
    "        validation_data: Optional[Dataset] = None,\n",
    "        num_workers: int = 0,\n",
    "        prefetch_factor: int = 2,\n",
    "        shuffle_buffer_length: Optional[int] = None,\n",
    "        cache_data: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        transformation = self.create_transformation()\n",
    "\n",
    "        trained_net = self.create_training_network(self.trainer.device)\n",
    "\n",
    "        input_names = get_module_forward_input_names(trained_net)\n",
    "\n",
    "        with env._let(max_idle_transforms=maybe_len(training_data) or 0):\n",
    "            training_instance_splitter = self.create_instance_splitter(\"training\")\n",
    "        training_iter_dataset = TransformedIterableDataset(\n",
    "            dataset=training_data,\n",
    "            transform=transformation\n",
    "            + training_instance_splitter\n",
    "            + SelectFields(input_names),\n",
    "            is_train=True,\n",
    "            shuffle_buffer_length=shuffle_buffer_length,\n",
    "            cache_data=cache_data,\n",
    "        )\n",
    "\n",
    "        if validation_data is not None:\n",
    "            with env._let(max_idle_transforms=maybe_len(validation_data) or 0):\n",
    "                validation_instance_splitter = self.create_instance_splitter(\"validation\")\n",
    "            validation_iter_dataset = TransformedIterableDataset(\n",
    "                dataset=validation_data,\n",
    "                transform=transformation\n",
    "                + validation_instance_splitter\n",
    "                + SelectFields(input_names),\n",
    "                is_train=True,\n",
    "                cache_data=cache_data,\n",
    "            )\n",
    "        return training_iter_dataset, validation_iter_dataset\n",
    "        \n",
    "from gluonts.env import env\n",
    "from gluonts.dataset.common import Dataset\n",
    "from typing import NamedTuple, Optional\n",
    "from gluonts.core.component import validated\n",
    "from gluonts.model.estimator import Estimator\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "from gluonts.transform import SelectFields, Transformation\n",
    "from gluonts.itertools import maybe_len\n",
    "\n",
    "lags_seq = None\n",
    "time_features = None\n",
    "\n",
    "training_net=training_net\n",
    "prediction_net=prediction_net\n",
    "noise=noise\n",
    "target_dim=target_dim\n",
    "prediction_length=dataset.metadata.prediction_length\n",
    "context_length=dataset.metadata.prediction_length\n",
    "cell_type='GRU'\n",
    "num_cells=num_cells\n",
    "hidden_dim=hidden_dim\n",
    "residual_layers=residual_layers\n",
    "input_size=target_dim * 4 + covariance_dim\n",
    "freq=dataset.metadata.freq\n",
    "loss_type='l2'\n",
    "scaling=True\n",
    "diff_steps=diffusion_steps\n",
    "beta_end=20 / diffusion_steps\n",
    "beta_schedule='linear'\n",
    "num_parallel_samples=100\n",
    "pick_incomplete=True\n",
    "\n",
    "class TrainOutput(NamedTuple):\n",
    "    transformation: Transformation\n",
    "    trained_net: nn.Module\n",
    "    predictor: PyTorchPredictor\n",
    "\n",
    "def create_transformation() -> Transformation:\n",
    "    return Chain(\n",
    "        [\n",
    "            AsNumpyArray(\n",
    "                field=FieldName.TARGET,\n",
    "                expected_ndim=2,\n",
    "            ),\n",
    "            # maps the target to (1, T)\n",
    "            # if the target data is uni dimensional\n",
    "            ExpandDimArray(\n",
    "                field=FieldName.TARGET,\n",
    "                axis=None,\n",
    "            ),\n",
    "            AddObservedValuesIndicator(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.OBSERVED_VALUES,\n",
    "            ),\n",
    "            AddTimeFeatures(\n",
    "                start_field=FieldName.START,\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                time_features=time_features,\n",
    "                pred_length=prediction_length,\n",
    "            ),\n",
    "            VstackFeatures(\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                input_fields=[FieldName.FEAT_TIME],\n",
    "            ),\n",
    "            SetFieldIfNotPresent(field=FieldName.FEAT_STATIC_CAT, value=[0]),\n",
    "            TargetDimIndicator(\n",
    "                field_name=\"target_dimension_indicator\",\n",
    "                target_field=FieldName.TARGET,\n",
    "            ),\n",
    "            AsNumpyArray(field=FieldName.FEAT_STATIC_CAT, expected_ndim=1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def create_instance_splitter(train_sampler,validation_sampler,mode: str):\n",
    "    assert mode in [\"training\", \"validation\", \"test\"]\n",
    "\n",
    "    instance_sampler = {\n",
    "        \"training\": train_sampler,\n",
    "        \"validation\": validation_sampler,\n",
    "        \"test\": TestSplitSampler(),\n",
    "    }[mode]\n",
    "\n",
    "    return InstanceSplitter(\n",
    "        target_field=FieldName.TARGET,\n",
    "        is_pad_field=FieldName.IS_PAD,\n",
    "        start_field=FieldName.START,\n",
    "        forecast_start_field=FieldName.FORECAST_START,\n",
    "        instance_sampler=instance_sampler,\n",
    "        past_length=history_length,\n",
    "        future_length=prediction_length,\n",
    "        time_series_fields=[\n",
    "            FieldName.FEAT_TIME,\n",
    "            FieldName.OBSERVED_VALUES,\n",
    "        ],\n",
    "    ) + (\n",
    "        RenameFields(\n",
    "            {\n",
    "                f\"past_{FieldName.TARGET}\": f\"past_{FieldName.TARGET}_cdf\",\n",
    "                f\"future_{FieldName.TARGET}\": f\"future_{FieldName.TARGET}_cdf\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def create_training_network(self, training_net, device: torch.device):\n",
    "    return training_net(\n",
    "        noise=self.noise,\n",
    "        input_size=self.input_size,\n",
    "        target_dim=self.target_dim,\n",
    "        num_layers=self.num_layers,\n",
    "        num_cells=self.num_cells,\n",
    "        cell_type=self.cell_type,\n",
    "        history_length=self.history_length,\n",
    "        context_length=self.context_length,\n",
    "        prediction_length=self.prediction_length,\n",
    "        dropout_rate=self.dropout_rate,\n",
    "        cardinality=self.cardinality,\n",
    "        embedding_dimension=self.embedding_dimension,\n",
    "        diff_steps=self.diff_steps,\n",
    "        loss_type=self.loss_type,\n",
    "        beta_end=self.beta_end,\n",
    "        beta_schedule=self.beta_schedule,\n",
    "        residual_layers=self.residual_layers,\n",
    "        residual_channels=self.residual_channels,\n",
    "        dilation_cycle_length=self.dilation_cycle_length,\n",
    "        lags_seq=self.lags_seq,\n",
    "        scaling=self.scaling,\n",
    "        conditioning_length=self.conditioning_length,\n",
    "        time_feat_dim=self.time_feat_dim,\n",
    "    ).to(device)\n",
    "\n",
    "lags_seq = (\n",
    "    lags_seq\n",
    "    if lags_seq is not None\n",
    "    else lags_for_fourier_time_features_from_frequency(freq_str=freq)\n",
    ")\n",
    "\n",
    "time_features = (\n",
    "    time_features\n",
    "    if time_features is not None\n",
    "    else fourier_time_features_from_frequency(freq)\n",
    ")\n",
    "\n",
    "history_length = context_length + max(lags_seq)\n",
    "pick_incomplete = pick_incomplete\n",
    "scaling = scaling\n",
    "\n",
    "train_sampler = ExpectedNumInstanceSampler(\n",
    "    num_instances=1.0,\n",
    "    min_past=0 if pick_incomplete else history_length,\n",
    "    min_future=prediction_length,\n",
    ")\n",
    "\n",
    "validation_sampler = ValidationSplitSampler(\n",
    "    min_past=0 if pick_incomplete else history_length,\n",
    "    min_future=prediction_length,\n",
    ") \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Optional\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gluonts.env import env\n",
    "from gluonts.core.component import validated\n",
    "from gluonts.dataset.common import Dataset\n",
    "from gluonts.model.estimator import Estimator\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "from gluonts.transform import SelectFields, Transformation\n",
    "from gluonts.itertools import maybe_len\n",
    "\n",
    "from pts import Trainer\n",
    "from pts.model import get_module_forward_input_names\n",
    "from pts.dataset.loader import TransformedIterableDataset\n",
    "\n",
    "class ScoreEstimatorLOAD(PyTorchEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        training_net: Callable,\n",
    "        prediction_net: Callable,\n",
    "        noise: str,\n",
    "        input_size: int,\n",
    "        freq: str,\n",
    "        prediction_length: int,\n",
    "        target_dim: int,\n",
    "        trainer: TrainerForecasting = TrainerForecasting(),\n",
    "        context_length: Optional[int] = None,\n",
    "        num_layers: int = 2,\n",
    "        num_cells: int = 40,\n",
    "        cell_type: str = \"GRU\",\n",
    "        num_parallel_samples: int = 100,\n",
    "        dropout_rate: float = 0.1,\n",
    "        cardinality: List[int] = [1],\n",
    "        embedding_dimension: int = 5,\n",
    "        hidden_dim: int = 100,\n",
    "        diff_steps: int = 100,\n",
    "        loss_type: str = \"l2\",\n",
    "        beta_end=0.1,\n",
    "        beta_schedule=\"linear\",\n",
    "        residual_layers=8,\n",
    "        residual_channels=8,\n",
    "        dilation_cycle_length=2,\n",
    "        scaling: bool = True,\n",
    "        pick_incomplete: bool = True,\n",
    "        lags_seq: Optional[List[int]] = None,\n",
    "        time_features: Optional[List[TimeFeature]] = None,\n",
    "        old: bool = False,\n",
    "        time_feat_dim: int = 4,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(trainer=trainer, **kwargs)\n",
    "\n",
    "        self.training_net = training_net\n",
    "        self.prediction_net = prediction_net\n",
    "        self.noise = noise\n",
    "\n",
    "        self.old = old\n",
    "\n",
    "        self.freq = freq\n",
    "        self.context_length = context_length if context_length is not None else prediction_length\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.target_dim = target_dim\n",
    "        self.time_feat_dim = time_feat_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_cells = num_cells\n",
    "        self.cell_type = cell_type\n",
    "        self.num_parallel_samples = num_parallel_samples\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.cardinality = cardinality\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "\n",
    "        self.conditioning_length = hidden_dim\n",
    "        self.diff_steps = diff_steps\n",
    "        self.loss_type = loss_type\n",
    "        self.beta_end = beta_end\n",
    "        self.beta_schedule = beta_schedule\n",
    "        self.residual_layers = residual_layers\n",
    "        self.residual_channels = residual_channels\n",
    "        self.dilation_cycle_length = dilation_cycle_length\n",
    "\n",
    "        self.lags_seq = (\n",
    "            lags_seq\n",
    "            if lags_seq is not None\n",
    "            else lags_for_fourier_time_features_from_frequency(freq_str=freq)\n",
    "        )\n",
    "\n",
    "        self.time_features = (\n",
    "            time_features\n",
    "            if time_features is not None\n",
    "            else fourier_time_features_from_frequency(self.freq)\n",
    "        )\n",
    "\n",
    "        self.history_length = self.context_length + max(self.lags_seq)\n",
    "        self.pick_incomplete = pick_incomplete\n",
    "        self.scaling = scaling\n",
    "\n",
    "        self.train_sampler = ExpectedNumInstanceSampler(\n",
    "            num_instances=1.0,\n",
    "            min_past=0 if pick_incomplete else self.history_length,\n",
    "            min_future=prediction_length,\n",
    "        )\n",
    "\n",
    "        self.validation_sampler = ValidationSplitSampler(\n",
    "            min_past=0 if pick_incomplete else self.history_length,\n",
    "            min_future=prediction_length,\n",
    "        )\n",
    "\n",
    "    def create_transformation(self) -> Transformation:\n",
    "        return Chain(\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.TARGET,\n",
    "                    expected_ndim=2,\n",
    "                ),\n",
    "                # maps the target to (1, T)\n",
    "                # if the target data is uni dimensional\n",
    "                ExpandDimArray(\n",
    "                    field=FieldName.TARGET,\n",
    "                    axis=None,\n",
    "                ),\n",
    "                AddObservedValuesIndicator(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.OBSERVED_VALUES,\n",
    "                ),\n",
    "                AddTimeFeatures(\n",
    "                    start_field=FieldName.START,\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.FEAT_TIME,\n",
    "                    time_features=self.time_features,\n",
    "                    pred_length=self.prediction_length,\n",
    "                ),\n",
    "                VstackFeatures(\n",
    "                    output_field=FieldName.FEAT_TIME,\n",
    "                    input_fields=[FieldName.FEAT_TIME],\n",
    "                ),\n",
    "                SetFieldIfNotPresent(field=FieldName.FEAT_STATIC_CAT, value=[0]),\n",
    "                TargetDimIndicator(\n",
    "                    field_name=\"target_dimension_indicator\",\n",
    "                    target_field=FieldName.TARGET,\n",
    "                ),\n",
    "                AsNumpyArray(field=FieldName.FEAT_STATIC_CAT, expected_ndim=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def create_instance_splitter(self, mode: str):\n",
    "        assert mode in [\"training\", \"validation\", \"test\"]\n",
    "\n",
    "        instance_sampler = {\n",
    "            \"training\": self.train_sampler,\n",
    "            \"validation\": self.validation_sampler,\n",
    "            \"test\": TestSplitSampler(),\n",
    "        }[mode]\n",
    "\n",
    "        return InstanceSplitter(\n",
    "            target_field=FieldName.TARGET,\n",
    "            is_pad_field=FieldName.IS_PAD,\n",
    "            start_field=FieldName.START,\n",
    "            forecast_start_field=FieldName.FORECAST_START,\n",
    "            instance_sampler=instance_sampler,\n",
    "            past_length=self.history_length,\n",
    "            future_length=self.prediction_length,\n",
    "            time_series_fields=[\n",
    "                FieldName.FEAT_TIME,\n",
    "                FieldName.OBSERVED_VALUES,\n",
    "            ],\n",
    "        ) + (\n",
    "            RenameFields(\n",
    "                {\n",
    "                    f\"past_{FieldName.TARGET}\": f\"past_{FieldName.TARGET}_cdf\",\n",
    "                    f\"future_{FieldName.TARGET}\": f\"future_{FieldName.TARGET}_cdf\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def create_training_network(self, device: torch.device):\n",
    "        return self.training_net(\n",
    "            noise=self.noise,\n",
    "            input_size=self.input_size,\n",
    "            target_dim=self.target_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            num_cells=self.num_cells,\n",
    "            cell_type=self.cell_type,\n",
    "            history_length=self.history_length,\n",
    "            context_length=self.context_length,\n",
    "            prediction_length=self.prediction_length,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            cardinality=self.cardinality,\n",
    "            embedding_dimension=self.embedding_dimension,\n",
    "            diff_steps=self.diff_steps,\n",
    "            loss_type=self.loss_type,\n",
    "            beta_end=self.beta_end,\n",
    "            beta_schedule=self.beta_schedule,\n",
    "            residual_layers=self.residual_layers,\n",
    "            residual_channels=self.residual_channels,\n",
    "            dilation_cycle_length=self.dilation_cycle_length,\n",
    "            lags_seq=self.lags_seq,\n",
    "            scaling=self.scaling,\n",
    "            conditioning_length=self.conditioning_length,\n",
    "            time_feat_dim=self.time_feat_dim,\n",
    "        ).to(device)\n",
    "\n",
    "    def create_predictor(\n",
    "        self,\n",
    "        transformation: Transformation,\n",
    "        trained_network: Any,\n",
    "        device: torch.device,\n",
    "    ) -> Predictor:\n",
    "        prediction_network = self.prediction_net(\n",
    "            noise=self.noise,\n",
    "            input_size=self.input_size,\n",
    "            target_dim=self.target_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            num_cells=self.num_cells,\n",
    "            cell_type=self.cell_type,\n",
    "            history_length=self.history_length,\n",
    "            context_length=self.context_length,\n",
    "            prediction_length=self.prediction_length,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            cardinality=self.cardinality,\n",
    "            embedding_dimension=self.embedding_dimension,\n",
    "            diff_steps=self.diff_steps,\n",
    "            loss_type=self.loss_type,\n",
    "            beta_end=self.beta_end,\n",
    "            beta_schedule=self.beta_schedule,\n",
    "            residual_layers=self.residual_layers,\n",
    "            residual_channels=self.residual_channels,\n",
    "            dilation_cycle_length=self.dilation_cycle_length,\n",
    "            lags_seq=self.lags_seq,\n",
    "            scaling=self.scaling,\n",
    "            conditioning_length=self.conditioning_length,\n",
    "            num_parallel_samples=self.num_parallel_samples,\n",
    "            time_feat_dim=self.time_feat_dim,\n",
    "        ).to(device)\n",
    "\n",
    "        copy_parameters(trained_network, prediction_network)\n",
    "        input_names = get_module_forward_input_names(prediction_network)\n",
    "        prediction_splitter = self.create_instance_splitter(\"test\")\n",
    "\n",
    "        return PyTorchPredictor(\n",
    "            input_transform=transformation + prediction_splitter,\n",
    "            input_names=input_names,\n",
    "            prediction_net=prediction_network,\n",
    "            batch_size=self.trainer.batch_size,\n",
    "            freq=self.freq,\n",
    "            prediction_length=self.prediction_length,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        training_data: Dataset,\n",
    "        validation_data: Optional[Dataset] = None,\n",
    "        num_workers: int = 0,\n",
    "        prefetch_factor: int = 2,\n",
    "        shuffle_buffer_length: Optional[int] = None,\n",
    "        cache_data: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        transformation = self.create_transformation()\n",
    "\n",
    "        trained_net = self.create_training_network(self.trainer.device)\n",
    "\n",
    "        input_names = get_module_forward_input_names(trained_net)\n",
    "\n",
    "        with env._let(max_idle_transforms=maybe_len(training_data) or 0):\n",
    "            validation_instance_splitter = self.create_instance_splitter(\"validation\")\n",
    "        training_iter_dataset = TransformedIterableDataset(\n",
    "            dataset=training_data,\n",
    "            transform=transformation\n",
    "            + validation_instance_splitter\n",
    "            + SelectFields(input_names),\n",
    "            is_train=True,\n",
    "            shuffle_buffer_length=shuffle_buffer_length,\n",
    "            cache_data=cache_data,\n",
    "        )\n",
    "\n",
    "        if validation_data is not None:\n",
    "            with env._let(max_idle_transforms=maybe_len(validation_data) or 0):\n",
    "                validation_instance_splitter = self.create_instance_splitter(\"validation\")\n",
    "            validation_iter_dataset = TransformedIterableDataset(\n",
    "                dataset=validation_data,\n",
    "                transform=transformation\n",
    "                + validation_instance_splitter\n",
    "                + SelectFields(input_names),\n",
    "                is_train=True,\n",
    "                cache_data=cache_data,\n",
    "            )\n",
    "\n",
    "        return training_iter_dataset, validation_iter_dataset\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        training_data: Dataset,\n",
    "        validation_data: Optional[Dataset] = None,\n",
    "        num_workers: int = 0,\n",
    "        prefetch_factor: int = 2,\n",
    "        shuffle_buffer_length: Optional[int] = None,\n",
    "        cache_data: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return self.train_model(\n",
    "            training_data,\n",
    "            validation_data,\n",
    "            num_workers=num_workers,\n",
    "            prefetch_factor=prefetch_factor,\n",
    "            shuffle_buffer_length=shuffle_buffer_length,\n",
    "            cache_data=cache_data,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_load = ScoreEstimatorLOAD(\n",
    "    training_net=training_net,\n",
    "    prediction_net=prediction_net,\n",
    "    noise=noise,\n",
    "    target_dim=target_dim,\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=dataset.metadata.prediction_length,\n",
    "    cell_type='GRU',\n",
    "    num_cells=num_cells,\n",
    "    hidden_dim=hidden_dim,\n",
    "    residual_layers=residual_layers,\n",
    "    input_size=target_dim * 4 + covariance_dim,\n",
    "    freq=dataset.metadata.freq,\n",
    "    loss_type='l2',\n",
    "    scaling=True,\n",
    "    diff_steps=diffusion_steps,\n",
    "    beta_end=20 / diffusion_steps,\n",
    "    beta_schedule='linear',\n",
    "    num_parallel_samples=100,\n",
    "    pick_incomplete=True,\n",
    "    trainer=TrainerForecasting(\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        num_batches_per_epoch=100,\n",
    "        batch_size=batch_size,\n",
    "        patience=10,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset  = estimator_load.train(dataset_train, dataset_val, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['target_dimension_indicator', 'past_time_feat', 'past_target_cdf', 'past_observed_values', 'past_is_pad', 'future_time_feat', 'future_target_cdf', 'future_observed_values'])\n"
     ]
    }
   ],
   "source": [
    "for i,data_entry in enumerate(val_dataset):\n",
    "    if i % 5000 == 0:\n",
    "        print(data_entry.keys())\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['target_dimension_indicator', 'past_time_feat', 'past_target_cdf', 'past_observed_values', 'past_is_pad', 'future_time_feat', 'future_target_cdf', 'future_observed_values'])\n"
     ]
    }
   ],
   "source": [
    "for i,data_entry in enumerate(train_dataset):\n",
    "    if i % 5000 == 0:\n",
    "        print(data_entry.keys())\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
