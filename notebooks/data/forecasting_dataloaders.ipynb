{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cesar\\anaconda3\\envs\\torchts\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from spflows.configs_classes.forecasting_configs import ForecastingModelConfig\n",
    "from spflows.data.datamodules import ForecastingDataModule\n",
    "\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.transform import (\n",
    "    Transformation,\n",
    "    Chain,\n",
    "    InstanceSplitter,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    ValidationSplitSampler,\n",
    "    TestSplitSampler,\n",
    "    RenameFields,\n",
    "    AsNumpyArray,\n",
    "    ExpandDimArray,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    VstackFeatures,\n",
    "    SetFieldIfNotPresent,\n",
    "    TargetDimIndicator,\n",
    ")\n",
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ForecastingModelConfig(prefetch_factor=None,\n",
    "                                batch_size=19)\n",
    "datamodule = ForecastingDataModule(config)\n",
    "datamodule.setup()\n",
    "config, all_datasets = ForecastingDataModule.get_data_and_update_config(config)\n",
    "training_data,test_data,validation_data = all_datasets\n",
    "dataset = get_dataset(config.dataset_str_name, regenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target', 'start', 'feat_static_cat'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][\"feat_static_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData(freq='h', target=None, feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat_0', cardinality='370')], feat_static_real=[], feat_dynamic_real=[], feat_dynamic_cat=[], prediction_length=24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5521,)\n"
     ]
    }
   ],
   "source": [
    "for idx,value in enumerate(islice(dataset.train,100)):\n",
    "    print(value[\"target\"].shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Tranforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pts.dataset.loader import TransformedIterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transforms =  Chain(\n",
    "    [\n",
    "        AsNumpyArray( #0\n",
    "            field=FieldName.TARGET,\n",
    "            expected_ndim=2,\n",
    "        ),\n",
    "        # maps the target to (1, T)\n",
    "        # if the target data is uni dimensional\n",
    "        ExpandDimArray( #1\n",
    "            field=FieldName.TARGET,\n",
    "            axis=None,\n",
    "        ),\n",
    "        AddObservedValuesIndicator( #2\n",
    "            target_field=FieldName.TARGET,\n",
    "            output_field=FieldName.OBSERVED_VALUES,\n",
    "        ),\n",
    "        AddTimeFeatures( #3\n",
    "            start_field=FieldName.START,\n",
    "            target_field=FieldName.TARGET,\n",
    "            output_field=FieldName.FEAT_TIME,\n",
    "            time_features=config.time_features,\n",
    "            pred_length=config.prediction_length,\n",
    "        ),\n",
    "        VstackFeatures( #4\n",
    "            output_field=FieldName.FEAT_TIME,\n",
    "            input_fields=[FieldName.FEAT_TIME],\n",
    "        ),\n",
    "        SetFieldIfNotPresent(field=FieldName.FEAT_STATIC_CAT, value=[0]), #5\n",
    "        TargetDimIndicator(#6\n",
    "            field_name=\"target_dimension_indicator\",\n",
    "            target_field=FieldName.TARGET,\n",
    "        ),\n",
    "        AsNumpyArray(field=FieldName.FEAT_STATIC_CAT, expected_ndim=1)#7\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations_2 = datamodule.create_instance_splitter(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iter_dataset = TransformedIterableDataset(\n",
    "            dataset=training_data,\n",
    "            transform=training_transforms+transformations_2,\n",
    "            is_train=True,\n",
    "            shuffle_buffer_length=config.shuffle_buffer_length,\n",
    "            cache_data=config.cache_data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_static_cat', 'past_time_feat', 'future_time_feat']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch = next(training_iter_dataset.__iter__())\n",
    "[k for k in databatch.keys() if \"feat\" in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch[\"feat_static_cat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "databatch = datamodule.get_train_databatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_dimension_indicator', 'past_time_feat', 'past_target_cdf', 'past_observed_values', 'past_is_pad', 'future_time_feat', 'future_target_cdf', 'future_observed_values'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 192, 370])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch[\"past_target_cdf\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 24, 370])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch[\"future_observed_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 370])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch[\"target_dimension_indicator\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.prediction_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
