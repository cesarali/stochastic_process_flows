{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cesar\\anaconda3\\envs\\torchts\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from spflows.configs_classes.forecasting_configs import ForecastingModelConfig\n",
    "from spflows.data.datamodules import ForecastingDataModule\n",
    "\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.transform import (\n",
    "    Transformation,\n",
    "    Chain,\n",
    "    InstanceSplitter,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    ValidationSplitSampler,\n",
    "    TestSplitSampler,\n",
    "    RenameFields,\n",
    "    AsNumpyArray,\n",
    "    ExpandDimArray,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    VstackFeatures,\n",
    "    SetFieldIfNotPresent,\n",
    "    TargetDimIndicator,\n",
    ")\n",
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ForecastingModelConfig(prefetch_factor=None,\n",
    "                                batch_size=19)\n",
    "datamodule = ForecastingDataModule(config)\n",
    "datamodule.setup()\n",
    "config, all_datasets = ForecastingDataModule.get_data_and_update_config(config)\n",
    "training_data,test_data,validation_data = all_datasets\n",
    "dataset = get_dataset(config.dataset_str_name, regenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': array([84.10138 , 93.31797 , 92.1659  , ..., 71.42857 , 52.99539 ,\n",
      "       52.419353], dtype=float32), 'start': Period('2014-01-14 00:00', 'H'), 'feat_static_cat': array([0]), 'item_id': 0}\n",
      "{'target': array([175.53192 , 164.89362 , 154.78723 , ..., 128.7234  , 129.78723 ,\n",
      "       116.489365], dtype=float32), 'start': Period('2014-01-01 00:00', 'H'), 'feat_static_cat': array([1]), 'item_id': 1}\n",
      "{'target': array([31.993204, 31.28539 , 31.568516, ..., 63.703285, 45.58324 ,\n",
      "       41.19479 ], dtype=float32), 'start': Period('2014-01-01 00:00', 'H'), 'feat_static_cat': array([2]), 'item_id': 2}\n",
      "{'target': array([56.265984, 55.20034 , 55.41347 , ..., 60.102303, 57.757885,\n",
      "       55.839725], dtype=float32), 'start': Period('2014-01-01 00:00', 'H'), 'feat_static_cat': array([3]), 'item_id': 3}\n",
      "{'target': array([47.902317, 49.624294, 44.45836 , ..., 43.5191  , 45.241077,\n",
      "       41.0144  ], dtype=float32), 'start': Period('2014-01-01 00:00', 'H'), 'feat_static_cat': array([4]), 'item_id': 4}\n",
      "{'target': array([27.983105, 27.719112, 27.719112, ..., 39.33474 , 39.07075 ,\n",
      "       38.278774], dtype=float32), 'start': Period('2014-01-01 00:00', 'H'), 'feat_static_cat': array([5]), 'item_id': 5}\n",
      "{'target': array([209.35869, 200.783  , 191.27516, ..., 435.30948, 413.87024,\n",
      "       426.7338 ], dtype=float32), 'start': Period('2014-01-01 00:00', 'H'), 'feat_static_cat': array([6]), 'item_id': 6}\n",
      "{'target': array([236.56345, 236.571  , 246.39728, ..., 511.0725 , 283.42902,\n",
      "       259.24472], dtype=float32), 'start': Period('2014-01-01 00:00', 'H'), 'feat_static_cat': array([7]), 'item_id': 7}\n",
      "{'target': array([ 6.930185,  6.930185,  6.930185, ..., 15.143737, 13.347023,\n",
      "       13.347023], dtype=float32), 'start': Period('2014-01-01 00:00', 'H'), 'feat_static_cat': array([8]), 'item_id': 8}\n"
     ]
    }
   ],
   "source": [
    "for idx,value in enumerate(islice(dataset.train,9)):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw From Crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spflows.data.gecko.gecko_requests import (\n",
    "    get_key\n",
    ")\n",
    "from spflows.data.gecko.gecko_metadata import AllCoinsMetadata,CoinMetadata\n",
    "from spflows.data.gecko.gecko_utils import get_dataframe_with_freq_bitcoin,get_dataframe_with_freq_from_bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:01<00:00, 70.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained 135 time series. Missing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "coingecko_key = get_key()\n",
    "date_string=\"2024-12-18\"\n",
    "\n",
    "all_coins_metadata = AllCoinsMetadata(date_string=date_string,coingecko_key=coingecko_key)\n",
    "all_coins_metadata.download_df_timeseries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins_not_bitcoin = [coin for coin in all_coins_metadata.df_time_series.keys() if coin != \"bitcoin\"]\n",
    "df = all_coins_metadata.df_time_series[coins_not_bitcoin[0]]\n",
    "df_bitcoin = all_coins_metadata.df_time_series[\"bitcoin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bitcoin_freq = get_dataframe_with_freq_bitcoin(df_bitcoin)\n",
    "df_freq = get_dataframe_with_freq_from_bitcoin(df,df_bitcoin_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from abc import abstractmethod\n",
    "from typing import (\n",
    "    Callable,\n",
    "    Dict,\n",
    "    List,\n",
    "    NamedTuple,\n",
    "    Optional,\n",
    "    Tuple,\n",
    "    Union,\n",
    "    cast,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gluonts.dataset.common import (\n",
    "    BasicFeatureInfo,\n",
    "    ArtificialDataset,\n",
    "    CategoricalFeatureInfo,\n",
    "    DataEntry,\n",
    "    Dataset,\n",
    "    ListDataset,\n",
    "    MetaData,\n",
    "    TrainDatasets,\n",
    ")\n",
    "\n",
    "def metadata(self) -> MetaData:\n",
    "    return MetaData(\n",
    "        freq=self.freq.freqstr, prediction_length=self.prediction_length\n",
    "    )\n",
    "\n",
    "class ArtificialDataset:\n",
    "    \"\"\"\n",
    "    Parent class of a dataset that can be generated from code.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, freq) -> None:\n",
    "        self.freq: BaseOffset = to_offset(freq)\n",
    "\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def metadata(self) -> MetaData:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def train(self) -> List[DataEntry]:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def test(self) -> List[DataEntry]:\n",
    "        pass\n",
    "\n",
    "    # todo return the same type as dataset repo for better usability\n",
    "    def generate(self) -> TrainDatasets:\n",
    "        return TrainDatasets(\n",
    "            metadata=self.metadata,\n",
    "            train=ListDataset(self.train, self.freq),\n",
    "            test=ListDataset(self.test, self.freq),\n",
    "        )\n",
    "\n",
    "class CoinDataset(ArtificialDataset):\n",
    "    \"\"\"\n",
    "    This dataset is set to behave exactly as the dataset\n",
    "    obtained from get_dataset in gluon_ts, it will generate 6 dimensions\n",
    "    index 0-2 bitcoin price, market_caps, total_volumes\n",
    "    index 3-5 altcoin price, market_caps, total_volumes\n",
    "\n",
    "    for portfolio creation prediction length is set to 96 hours (4 days)\n",
    "    freq in hours H\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 coin_id,\n",
    "                 df_freq,\n",
    "                 df_bitcoin_freq,\n",
    "                 prediction_length: int = 96,  # change for days (portfolio sensitivity)\n",
    "                 freq_str: str = \"H\",\n",
    "                 include_market_cap: bool = True,\n",
    "                 include_volumes: bool = True):\n",
    "        \"\"\"\n",
    "        df_freq: pd.DataFrame\n",
    "        df_bitcoin_freq: pd.DataFrame\n",
    "        \"\"\"\n",
    "        super().__init__(freq_str)\n",
    "        self.coin_id = coin_id\n",
    "        self.df_freq = df_freq\n",
    "        self.df_bitcoin_freq = df_bitcoin_freq\n",
    "        self.prediction_length = prediction_length\n",
    "        self.include_market_cap = include_market_cap\n",
    "        self.include_volumes = include_volumes\n",
    "        self._set_data_entries()\n",
    "\n",
    "    def metadata(self):\n",
    "        return MetaData(freq=self.freq_str,\n",
    "                        feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat_0', cardinality='6')],\n",
    "                        prediction_length=self.prediction_length)\n",
    "\n",
    "    def _set_data_entries(self):\n",
    "        \"\"\"\n",
    "        Set data entries for the dataset.\n",
    "        \"\"\"\n",
    "        alt_coin_prices = self.df_freq[\"prices\"].values\n",
    "        alt_coin_market_caps = self.df_freq[\"market_caps\"].values\n",
    "        alt_coin_total_volumes = self.df_freq[\"total_volumes\"].values\n",
    "\n",
    "        bitcoin_prices = self.df_bitcoin_freq[\"prices\"].values\n",
    "        bitcoin_market_caps = self.df_bitcoin_freq[\"market_caps\"].values\n",
    "        bitcoin_total_volumes = self.df_bitcoin_freq[\"total_volumes\"].values\n",
    "\n",
    "        timestamp = self.df_bitcoin_freq.index[0]\n",
    "        period = timestamp.to_period(freq='H')\n",
    "\n",
    "        self.data_list = [\n",
    "            {'target': bitcoin_prices, 'start': period, 'feat_static_cat': np.array([0]), 'item_id': 0},\n",
    "            {'target': bitcoin_market_caps, 'start': period, 'feat_static_cat': np.array([0]), 'item_id': 1},\n",
    "            {'target': bitcoin_total_volumes, 'start': period, 'feat_static_cat': np.array([0]), 'item_id': 2},\n",
    "            {'target': alt_coin_prices, 'start': period, 'feat_static_cat': np.array([0]), 'item_id': 3},\n",
    "            {'target': alt_coin_market_caps, 'start': period, 'feat_static_cat': np.array([0]), 'item_id': 4},\n",
    "            {'target': alt_coin_total_volumes, 'start': period, 'feat_static_cat': np.array([0]), 'item_id': 5}\n",
    "        ]\n",
    "\n",
    "    def train(self):\n",
    "        return self.data_list\n",
    "\n",
    "    def test(self):\n",
    "        return self.data_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
